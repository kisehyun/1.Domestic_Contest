{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c9465fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from haversine import haversine\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "834f57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('./train.parquet')\n",
    "test = pd.read_parquet('./test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30db65",
   "metadata": {},
   "source": [
    "- 불필요한 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e15c23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['vehicle_restricted', 'id', 'height_restricted'], axis = 1, inplace = True)\n",
    "test.drop(['vehicle_restricted', 'id', 'height_restricted'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3c4c7",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "\n",
    "### 1. 도로 주변 시설 및 구역 수(train 기준)\n",
    "\n",
    "#### 공공 데이터 포털에서 2022년 8월 이전 아래 5가지 표준 데이터를 사용하였습니다.\n",
    "- 무인교통단속카메라\n",
    "- 전국초중등학교기본정보\n",
    "- 어린이보호구역\n",
    "- 제주시 주차장 정보\n",
    "- 서귀포시 주차장 정보\n",
    "\n",
    "train의 start_node, end_node의 위경도 좌표의 unique 값만을 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0970e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_comb = train[['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7759e8",
   "metadata": {},
   "source": [
    "- 무인교통단속카메라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6667142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cctv = pd.read_csv('경찰청_제주특별자치도경찰청_무인교통단속카메라_20220616.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2ec0fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cctv = cctv.iloc[:, 3:-7].drop(['소재지도로명주소', '소재지지번주소'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19574dd4",
   "metadata": {},
   "source": [
    "- 초중등학교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b5210a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "school = pd.read_csv('초중등학교.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2cd10406",
   "metadata": {},
   "outputs": [],
   "source": [
    "school = school[(school['데이터기준일자'] <= '2022-07-31') & (school['시도교육청명'].str.contains('제주'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a620fd",
   "metadata": {},
   "source": [
    "- 어린이 보호 구역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "81ad21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "child = pd.read_csv('제주특별자치도_어린이보호구역_20220513.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5796aaca",
   "metadata": {},
   "source": [
    "- 제주시 주차장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c1b5ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking1 = pd.read_csv(\"제주특별자치도_제주시_주차장정보_20210818_1630391997093_77385.csv\", encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e65249bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking1.dropna(subset = ['위도', '경도'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7a346",
   "metadata": {},
   "source": [
    "- 서귀포시 주차장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e6069f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking2 = pd.read_csv(\"제주특별자치도_서귀포시_주차장정보_20220425_1650966840250_33855.csv\", encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c127ff6",
   "metadata": {},
   "source": [
    "직선과 점 사이의 거리 방정식 활용\n",
    "- 위의 4가지 데이터에 존재하는 시설 및 구역의 위경도 좌표(점)과 train 데이터에 존재하는 각 도로의 위경도 좌표(start_node, end_node)를 잇는 직선의 거리를 구하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "84dadfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_dist(x1, y1, x2, y2, a, b):\n",
    "    \n",
    "    area = abs((x1 - a) * (y2 - b) - (y1 - b) * (x2 - a))\n",
    "    AB = ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n",
    "    distance = area / AB\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972737cd",
   "metadata": {},
   "source": [
    "train 데이터의 위경도 쌍을 이은 직선과 각 시설 및 구역의 위경도 좌표의 거리(위경도 좌표상 거리)가 0.0005이내일 경우 해당 도로 주변에 있다고 간주하여 count +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9a2459a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_cnt(gps_values, infra_values) :\n",
    "    \n",
    "    cnt = []\n",
    "\n",
    "    for y1, x1, y2, x2 in gps_values.values :\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a, b in infra_values.values :\n",
    "\n",
    "            dist = cal_dist(x1, y1, x2, y2, a, b)\n",
    "\n",
    "            if dist < 0.0005 :\n",
    "                i += 1\n",
    "\n",
    "            else :\n",
    "                pass\n",
    "        cnt.append(i)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f3744b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cctv_cnt = get_node_cnt(gps_comb, cctv[['경도', '위도']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9f7cdf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_cnt = get_node_cnt(gps_comb, school[['경도', '위도']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8a89ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_cnt = get_node_cnt(gps_comb, child[['경도', '위도']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1eef7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking1_cnt = get_node_cnt(gps_comb, parking1[['경도', '위도']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8b2d5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking2_cnt = get_node_cnt(gps_comb, parking2[['경도', '위도']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "adb57e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_cnt = list(np.array(parking1_cnt) + np.array(parking2_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "35c2391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_comb['CCTV_cnt'] = cctv_cnt\n",
    "gps_comb['school_cnt'] = school_cnt\n",
    "gps_comb['child_cnt'] = child_cnt\n",
    "gps_comb['parking_cnt'] = parking_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68153a3f",
   "metadata": {},
   "source": [
    "#### 각 데이터에 merge 후 fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fb26b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, gps_comb, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7ad631e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test, gps_comb, how = 'left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08f828",
   "metadata": {},
   "source": [
    "### 2. 제주 공항까지 거리(km)\n",
    "\n",
    "- train과 test의 시작 위경도 좌표와 제주 공항 위경도 좌표까지의 거리(km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8dcf1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jeju = 33.506683, 126.493177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1c4e012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['j_a_dist'] = [haversine((v[0], v[1]), jeju, unit = 'km') for v in train[['start_latitude', 'start_longitude']].values]\n",
    "test['j_a_dist'] = [haversine((v[0], v[1]), jeju, unit = 'km') for v in test[['start_latitude', 'start_longitude']].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d00107",
   "metadata": {},
   "source": [
    "### 3. 한라산까지 거리(km)\n",
    "\n",
    "- train과 test의 시작 위경도 좌표와 한라산 위경도 좌표까지의 거리(km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "937253ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hanla = 33.36168194, 126.5291548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3d42d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['h_a_dist'] = [haversine((v[0], v[1]), hanla, unit = 'km') for v in train[['start_latitude', 'start_longitude']].values]\n",
    "test['h_a_dist'] = [haversine((v[0], v[1]), hanla, unit = 'km') for v in test[['start_latitude', 'start_longitude']].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2bdd4",
   "metadata": {},
   "source": [
    "### 4. start_node_name과 end_node_name을 key값으로 만들어 LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "53d6332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ddd7c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['node_combination'] = train['start_node_name'] + '_' + train['end_node_name']\n",
    "test['node_combination'] = test['start_node_name'] + '_' + test['end_node_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "aa311e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['node_combination'] = le.fit_transform(train['node_combination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e4d58f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in np.unique(test['node_combination']) :\n",
    "    if category not in le.classes_ :\n",
    "        le.classes_ = np.append(le.classes_, label)\n",
    "test['node_combination'] = le.transform(test['node_combination'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5401bfe",
   "metadata": {},
   "source": [
    "### 5. 위경도 좌표만으로 Clustering(KMeans)\n",
    "- Clustering Plotting 결과 군집 수가 6일 때 각 좌표가 명확히 구분되어 6으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5a55de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_train = train[['start_node_name', 'start_latitude', 'start_longitude', 'end_node_name', 'end_latitude', 'end_longitude']].drop_duplicates()\n",
    "dup_test = test[['start_node_name', 'start_latitude', 'start_longitude', 'end_node_name', 'end_latitude', 'end_longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1e7ddc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters = 6, max_iter = 1000, random_state = 42, n_init = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5f39de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_train['gps_cls'] = km.fit_predict(dup_train.iloc[:, [1, 2, 4, 5]])\n",
    "dup_test['gps_cls'] = km.predict(dup_test.iloc[:, [1, 2, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "50002a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, dup_train, how = 'left')\n",
    "test = pd.merge(test, dup_test, how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238b837",
   "metadata": {},
   "source": [
    "### 6. 공휴일 전후 1 ~ 2일 여부\n",
    "\n",
    "- 일반적인 공휴일 기준으로 전후 1 ~ 2일을 기간을 더 두어 binary화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "93930e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['base_date'] = train['base_date'].astype(str)\n",
    "test['base_date'] = test['base_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5e9350d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = train['base_date'].str[4:]\n",
    "test['date'] = test['base_date'].str[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "89ea7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_days = ['0129', '0130', '0131', '0201', '0202', '1231', '0101', '0102', '0228', '0230', '0301', '0302', '0504',\n",
    "          '0505', '0506', '0507', '0508', '0605', '0607', '0606', '0920', '0921', '0922', '0814', '0815', '0816',\n",
    "          '1002', '1003', '1004', '1008', '1009', '1010', '1224', '1225', '1226']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5782a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['in_h_days'] = train['date'].isin(h_days)\n",
    "test['in_h_days'] = test['date'].isin(h_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195516a",
   "metadata": {},
   "source": [
    "### 7. 년도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a610c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['base_date'] = pd.to_datetime(train['base_date'])\n",
    "test['base_date'] = pd.to_datetime(test['base_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "54f8bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year'] = train['base_date'].dt.year\n",
    "test['year'] = test['base_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001bae7a",
   "metadata": {},
   "source": [
    "### 8. 월"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a2643ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train['base_date'].dt.month\n",
    "test['month'] = test['base_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831e921",
   "metadata": {},
   "source": [
    "### 9. 최고 제한 속도로 도로 주행시 소요 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "dedd1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = []\n",
    "for i, v in enumerate(train[['start_latitude', 'end_latitude', 'start_longitude', 'end_longitude']].values) :\n",
    "    dist.append(haversine((v[0], v[2]), (v[1], v[3]), unit = 'km'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "74398393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['at_time'] = 60 * pd.Series(dist) / train['maximum_speed_limit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "62ac861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = []\n",
    "for i, v in enumerate(test[['start_latitude', 'end_latitude', 'start_longitude', 'end_longitude']].values) :\n",
    "    dist.append(haversine((v[0], v[2]), (v[1], v[3]), unit = 'km'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4f43ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['at_time'] = 60 * pd.Series(dist) / test['maximum_speed_limit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ed2ebf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2185"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0979c2ea",
   "metadata": {},
   "source": [
    "### 9. 방위각\n",
    "- 각 도로의 start, end node의 위경도 좌표로 해당 도로의 방위각 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d12f2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Azimuth(lat1, lng1, lat2, lng2):\n",
    "    Lat1 = math.radians(lat1)\n",
    "    Lat2 = math.radians(lat2)\n",
    "    Lng1 = math.radians(lng1)\n",
    "    Lng2 = math.radians(lng2)\n",
    "    \n",
    "    y = math.sin(Lng2 - Lng1) * math.cos(Lat2)\n",
    "    x = math.cos(Lat1) * math.sin(Lat2) - math.sin(Lat1) * math.cos(Lat2) * math.cos(Lng2-Lng1)\n",
    "    z = math.atan2(y, x)\n",
    "\n",
    "    a = np.rad2deg(z)\n",
    "    \n",
    "    if(a < 0):\n",
    "        a = 180 + (180 + a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "1911f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['degree'] = [Azimuth(v[0], v[1], v[2], v[3]) for i, v in enumerate(train[['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude']].values)]\n",
    "test['degree'] = [Azimuth(v[0], v[1], v[2], v[3]) for i, v in enumerate(test[['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude']].values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe5225",
   "metadata": {},
   "source": [
    "### 10. 계절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "91ea5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(x) :\n",
    "    \n",
    "    if x in [9, 10, 11] :\n",
    "        return 3\n",
    "    elif x in [12, 1, 2] :\n",
    "        return 2\n",
    "    elif x in [3, 4, 5, 6] :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "70db02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['season'] = train['month'].apply(get_season)\n",
    "test['season'] = test['month'].apply(get_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270fcdfb",
   "metadata": {},
   "source": [
    "### 11. 요일\n",
    "- 일반적인 요일 순서대로가 아닌 LabelEncoding으로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6338dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day_of_week'] = le.fit_transform(train['day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f7b2d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in np.unique(test['day_of_week']) :\n",
    "    if category not in le.classes_ :\n",
    "        le.classes_ = np.append(le.classes_, label)\n",
    "test['day_of_week'] = le.transform(test['day_of_week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d5735",
   "metadata": {},
   "source": [
    "### 12. 도로명\n",
    "- 도로명 LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1828226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['road_name'] = le.fit_transform(train['road_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4d66a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in np.unique(test['road_name']) :\n",
    "    if category not in le.classes_ :\n",
    "        le.classes_ = np.append(le.classes_, label)\n",
    "test['road_name'] = le.transform(test['road_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88c33e",
   "metadata": {},
   "source": [
    "### 13. 시작 노드 == 종료 노드 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8df9f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['node_same'] = train['start_node_name'] == train['end_node_name']\n",
    "test['node_same'] = test['start_node_name'] == test['end_node_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea0ace",
   "metadata": {},
   "source": [
    "### 14. 기타 컬럼 LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3fbe03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['start_turn_restricted'] = le.fit_transform(train['start_turn_restricted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "edf51834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in np.unique(test['start_turn_restricted']) :\n",
    "    if category not in le.classes_ :\n",
    "        le.classes_ = np.append(le.classes_, label)\n",
    "test['start_turn_restricted'] = le.transform(test['start_turn_restricted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "dd268342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['end_turn_restricted'] = le.fit_transform(train['end_turn_restricted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a823d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in np.unique(test['end_turn_restricted']) :\n",
    "    if category not in le.classes_ :\n",
    "        le.classes_ = np.append(le.classes_, label)\n",
    "test['end_turn_restricted'] = le.transform(test['end_turn_restricted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda551a",
   "metadata": {},
   "source": [
    "#### 모델링 사용 제외 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cea5b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['start_node_name', 'end_node_name', 'date', 'base_date'], axis = 1, inplace = True)\n",
    "test.drop(['start_node_name', 'end_node_name', 'date', 'base_date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe778933",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Modeling\n",
    "\n",
    "- lane_count를 1, 2, 3으로 나누어 모델링\n",
    "- LGBM, XGBoost는 optuna로 파라미터 튜닝 -> pkl로 save, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7c496606",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d521f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9d8eeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d2cbab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 6, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1f665635",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[X['lane_count'] == 1].drop(['lane_count'], axis = 1)\n",
    "X2 = X[X['lane_count'] == 2].drop(['lane_count'], axis = 1)\n",
    "X3 = X[X['lane_count'] == 3].drop(['lane_count'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b5bf04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y[X1.index]\n",
    "y2 = y[X2.index]\n",
    "y3 = y[X3.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "03d537e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard1 = X1['day_of_week']\n",
    "standard2 = X2['day_of_week']\n",
    "standard3 = X3['day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dd5341c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "01dec908",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = target.loc[target['lane_count'] == 1, X1.columns]\n",
    "target2 = target.loc[target['lane_count'] == 2, X2.columns]\n",
    "target3 = target.loc[target['lane_count'] == 3, X3.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.random.randint(0, 2022, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a574ad",
   "metadata": {},
   "source": [
    "### 1) CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_pred1 = np.zeros(target1.shape[0])\n",
    "train_cb_pred1 = np.zeros(X1.shape[0])\n",
    "\n",
    "i = 0\n",
    "\n",
    "cb_mae = []\n",
    "train_cb_mae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X1, standard1):\n",
    "    tr_x, tr_y = X1.iloc[tr_idx], y1.iloc[tr_idx]\n",
    "    val_x, val_y = X1.iloc[val_idx], y1.iloc[val_idx]\n",
    "\n",
    "    cb = CatBoostRegressor(max_depth = 8, learning_rate = 0.033,\n",
    "                           use_best_model = True, iterations = 10000, eval_metric = 'MAE')\n",
    "\n",
    "    cb.fit(tr_x, tr_y, eval_set=[(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds=5, verbose=2500)\n",
    "\n",
    "    val_pred = cb.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    cb_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = cb.predict(target1) / skf.n_splits\n",
    "    cb_pred1 += fold_pred\n",
    "\n",
    "    train_fold_pred = cb.predict(X1) / skf.n_splits\n",
    "    train_cb_pred1 += train_fold_pred\n",
    "    \n",
    "print(f\"AVG of MAE = {np.mean(cb_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9784de",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cb_pred1', cb_pred1)\n",
    "np.save('train_cb_pred1', train_cb_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_pred2 = np.zeros(target2.shape[0])\n",
    "train_cb_pred2 = np.zeros(X2.shape[0])\n",
    "\n",
    "i = 0\n",
    "\n",
    "cb_mae = []\n",
    "train_cb_mae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X2, standard2):\n",
    "    tr_x, tr_y = X2.iloc[tr_idx], y2.iloc[tr_idx]\n",
    "    val_x, val_y = X2.iloc[val_idx], y2.iloc[val_idx]\n",
    "\n",
    "    cb = CatBoostRegressor(max_depth = 8, learning_rate = 0.033,\n",
    "                           use_best_model = True, iterations = 10000, eval_metric = 'MAE')\n",
    "\n",
    "    cb.fit(tr_x, tr_y, eval_set=[(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds=5, verbose=2500)\n",
    "\n",
    "    val_pred = cb.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    cb_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\\n\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = cb.predict(target2) / skf.n_splits\n",
    "    cb_pred2 += fold_pred\n",
    "\n",
    "    train_fold_pred = cb.predict(X2) / skf.n_splits\n",
    "    train_cb_pred2 += train_fold_pred\n",
    "\n",
    "print(f\"AVG of MAE = {np.mean(cb_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cb_pred2', cb_pred2)\n",
    "np.save('train_cb_pred2', train_cb_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b896261",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_pred3 = np.zeros(target3.shape[0])\n",
    "train_cb_pred3 = np.zeros(X3.shape[0])\n",
    "\n",
    "i = 0\n",
    "\n",
    "cb_mae = []\n",
    "train_cb_mae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X3, standard3):\n",
    "    tr_x, tr_y = X3.iloc[tr_idx], y3.iloc[tr_idx]\n",
    "    val_x, val_y = X3.iloc[val_idx], y3.iloc[val_idx]\n",
    "\n",
    "    cb = CatBoostRegressor(max_depth = 8, learning_rate = 0.033,\n",
    "                           use_best_model = True, iterations = 10000, eval_metric = 'MAE')\n",
    "\n",
    "    cb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 8, verbose = 2500)\n",
    "\n",
    "    val_pred = cb.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    cb_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\\n\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = cb.predict(target3) / skf.n_splits\n",
    "    cb_pred3 += fold_pred\n",
    "\n",
    "    train_fold_pred = cb.predict(X3) / skf.n_splits\n",
    "    train_cb_pred3 += train_fold_pred\n",
    "\n",
    "print(f\"AVG of MAE = {np.mean(cb_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ed599",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cb_pred3', cb_pred3)\n",
    "np.save('train_cb_pred3', train_cb_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd206b09",
   "metadata": {},
   "source": [
    "### 2) LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87125856",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred1 = np.zeros(target1.shape[0])\n",
    "train_lgbm_pred1 = np.zeros(X1.shape[0])\n",
    "\n",
    "i = 0\n",
    "\n",
    "lgbm_mae = []\n",
    "train_lgbm_mae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X1, standard1):\n",
    "    tr_x, tr_y = X1.iloc[tr_idx], y1.iloc[tr_idx]\n",
    "    val_x, val_y = X1.iloc[val_idx], y1.iloc[val_idx]\n",
    "\n",
    "    study = joblib.load(f'./LGBMRegressor_tune/tune_0.pkl')\n",
    "    print('Study loaded')\n",
    "    print(study.best_trial.params)\n",
    "    lgbm = LGBMRegressor(**study.best_trial.params)\n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 5, verbose = 2500)\n",
    "\n",
    "    val_pred = lgbm.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    lgbm_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = lgbm.predict(target1) / skf.n_splits\n",
    "    lgbm_pred1 += fold_pred\n",
    "\n",
    "    train_fold_pred = lgbm.predict(X1) / skf.n_splits\n",
    "    train_lgbm_pred1 += train_fold_pred\n",
    "\n",
    "print(f\"AVG of MAE = {np.mean(lgbm_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lgbm_pred1', lgbm_pred1)\n",
    "np.save('train_lgbm_pred1', train_lgbm_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred2 = np.zeros(target2.shape[0])\n",
    "train_lgbm_pred2 = np.zeros(X2.shape[0])\n",
    "\n",
    "i = 0\n",
    "\n",
    "lgbm_mae = []\n",
    "train_lgbm_mae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X2, standard2):\n",
    "    tr_x, tr_y = X2.iloc[tr_idx], y2.iloc[tr_idx]\n",
    "    val_x, val_y = X2.iloc[val_idx], y2.iloc[val_idx]\n",
    "\n",
    "    study = joblib.load(f'./LGBMRegressor_tune/tune_1.pkl')\n",
    "    print('Study loaded')\n",
    "    print(study.best_trial.params)\n",
    "    lgbm = LGBMRegressor(**study.best_trial.params)\n",
    "\n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds=5, verbose=2500)\n",
    "\n",
    "    val_pred = lgbm.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    lgbm_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\\n\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = lgbm.predict(target2) / skf.n_splits\n",
    "    lgbm_pred2 += fold_pred\n",
    "\n",
    "    train_fold_pred = lgbm.predict(X2) / skf.n_splits\n",
    "    train_lgbm_pred2 += train_fold_pred\n",
    "\n",
    "print(f\"AVG of MAE = {np.mean(lgbm_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lgbm_pred2', lgbm_pred2)\n",
    "np.save('train_lgbm_pred2', train_lgbm_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred3 = np.zeros(target3.shape[0])\n",
    "train_lgbm_pred3 = np.zeros(X3.shape[0])\n",
    "\n",
    "i = 0\n",
    "lgbm_mae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X3, standard3):\n",
    "    tr_x, tr_y = X3.iloc[tr_idx], y3.iloc[tr_idx]\n",
    "    val_x, val_y = X3.iloc[val_idx], y3.iloc[val_idx]\n",
    "\n",
    "    study = joblib.load(f'./LGBMRegressor_tune/tune_2.pkl')\n",
    "    print('Study loaded')\n",
    "    print(study.best_trial.params)\n",
    "    lgbm = LGBMRegressor(**study.best_trial.params)\n",
    "\n",
    "    lgbm.fit(tr_x, tr_y, eval_set=[(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds=8, verbose=2500)\n",
    "\n",
    "    val_pred = lgbm.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    lgbm_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\\n\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = lgbm.predict(target3) / skf.n_splits\n",
    "    lgbm_pred3 += fold_pred\n",
    "\n",
    "    train_fold_pred = lgbm.predict(X3) / skf.n_splits\n",
    "    train_lgbm_pred3 += train_fold_pred\n",
    "\n",
    "print(f\"AVG of MAE = {np.mean(lgbm_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lgbm_pred3', lgbm_pred3)\n",
    "np.save('train_lgbm_pred3', train_lgbm_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67106fda",
   "metadata": {},
   "source": [
    "### 3) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed21378",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred1 = np.zeros(target1.shape[0])\n",
    "train_xgb_pred1 = np.zeros(X1.shape[0])\n",
    "\n",
    "i = 0\n",
    "\n",
    "xgb_mae = []\n",
    "for tr_idx, val_idx in skf.split(X1, standard1):\n",
    "    tr_x, tr_y = X1.iloc[tr_idx], y1.iloc[tr_idx]\n",
    "    val_x, val_y = X1.iloc[val_idx], y1.iloc[val_idx]\n",
    "\n",
    "    study = joblib.load(f'./XGBRegressor_tune/tune_0.pkl')\n",
    "    print('Study loaded')\n",
    "    print(study.best_trial.params)\n",
    "    xgb = XGBRegressor(**study.best_trial.params)\n",
    "\n",
    "    xgb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds=8, verbose=1000,\n",
    "            eval_metric='mae')\n",
    "\n",
    "    val_pred = xgb.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    xgb_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = xgb.predict(target1) / skf.n_splits\n",
    "    xgb_pred1 += fold_pred\n",
    "\n",
    "    train_fold_pred = xgb.predict(X1) / skf.n_splits\n",
    "    train_xgb_pred1 += train_fold_pred\n",
    "\n",
    "print(f\"\\nAVG of MAE = {np.mean(xgb_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('xgb_pred1', xgb_pred1)\n",
    "np.save('train_xgb_pred1', train_xgb_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ac240",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred2 = np.zeros(target2.shape[0])\n",
    "train_xgb_pred2 = np.zeros(X2.shape[0])\n",
    "\n",
    "i = 0\n",
    "xgb_mae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X2, standard2):\n",
    "    tr_x, tr_y = X2.iloc[tr_idx], y2.iloc[tr_idx]\n",
    "    val_x, val_y = X2.iloc[val_idx], y2.iloc[val_idx]\n",
    "\n",
    "    study = joblib.load(f'./XGBRegressor_tune/tune_1.pkl')\n",
    "    print('Study loaded')\n",
    "    print(study.best_trial.params)\n",
    "    xgb = XGBRegressor(**study.best_trial.params)\n",
    "\n",
    "    xgb.fit(tr_x, tr_y, eval_set=[(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds=8, verbose=1000,\n",
    "            eval_metric='mae')\n",
    "\n",
    "    val_pred = xgb.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    xgb_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = xgb.predict(target2) / skf.n_splits\n",
    "    xgb_pred2 += fold_pred\n",
    "\n",
    "    train_fold_pred = xgb.predict(X2) / skf.n_splits\n",
    "    train_xgb_pred2 += train_fold_pred\n",
    "\n",
    "print(f\"\\nAVG of MAE = {np.mean(xgb_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('xgb_pred2', xgb_pred2)\n",
    "np.save('train_xgb_pred2', train_xgb_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30752bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred3 = np.zeros(target3.shape[0])\n",
    "train_xgb_pred3 = np.zeros(X3.shape[0])\n",
    "\n",
    "i = 0\n",
    "xgb_mae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X3, standard3):\n",
    "    tr_x, tr_y = X3.iloc[tr_idx], y3.iloc[tr_idx]\n",
    "    val_x, val_y = X3.iloc[val_idx], y3.iloc[val_idx]\n",
    "\n",
    "    study = joblib.load(f'./XGBRegressor_tune/tune_2.pkl')\n",
    "    print('Study loaded')\n",
    "    print(study.best_trial.params)\n",
    "    xgb = XGBRegressor(**study.best_trial.params)\n",
    "\n",
    "    xgb.fit(tr_x, tr_y, eval_set=[(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 8, verbose = 1000,\n",
    "            eval_metric = 'mae')\n",
    "\n",
    "    val_pred = xgb.predict(val_x).astype(int)\n",
    "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
    "    xgb_mae.append(fold_mae)\n",
    "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = xgb.predict(target3) / skf.n_splits\n",
    "    xgb_pred3 += fold_pred\n",
    "\n",
    "    train_fold_pred = xgb.predict(X3) / skf.n_splits\n",
    "    train_xgb_pred3 += train_fold_pred\n",
    "\n",
    "print(f\"\\nAVG of MAE = {np.mean(xgb_mae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('xgb_pred3', xgb_pred3)\n",
    "np.save('train_xgb_pred3', train_xgb_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13924b3",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30546046",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983846a",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e890695",
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost\n",
    "xgb_pred1 = np.load('./xgb_pred1.npy')\n",
    "xgb_pred2 = np.load('./xgb_pred2.npy')\n",
    "xgb_pred3 = np.load('./xgb_pred3.npy')\n",
    "\n",
    "### LGBM\n",
    "lgbm_pred1 = np.load('./lgbm_pred1.npy')\n",
    "lgbm_pred2 = np.load('./lgbm_pred2.npy')\n",
    "lgbm_pred3 = np.load('./lgbm_pred3.npy')\n",
    "\n",
    "### CatBoost\n",
    "cb_pred1 = np.load('./cb_pred1.npy')\n",
    "cb_pred2 = np.load('./cb_pred2.npy')\n",
    "cb_pred3 = np.load('./cb_pred3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble - LGBM : XGBoost : CatBoost = 0.65 : 0.25 : 0.1\n",
    "submission.loc[target1.index, 'target'] = lg_pred1 * 0.65 + xgb_pred1 * 0.25 + cb_pred1 * 0.1\n",
    "submission.loc[target2.index, 'target'] = lg_pred1 * 0.65 + xgb_pred2 * 0.25 + cb_pred2 * 0.1\n",
    "submission.loc[target3.index, 'target'] = lg_pred1 * 0.65 + xgb_pred3 * 0.25 + cb_pred3 * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b511c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = round(submission['target'], 0)\n",
    "submission.to_csv('lgbm_xgb_cb.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
