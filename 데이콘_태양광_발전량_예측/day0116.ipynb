{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Energy Generation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import os\n",
    "from lightgbm import LGBMRegressor\n",
    "import datetime\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from itertools import chain, repeat\n",
    "from tqdm.notebook import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/kisehyun/Competition/데이콘_태양광 발전량 예측/train/train.csv')\n",
    "\n",
    "for i in range(81) :\n",
    "    globals() [f'test_{i}'] = pd.read_csv(f'/Users/kisehyun/Competition/데이콘_태양광 발전량 예측/test/{i}.csv')\n",
    "    globals() [f'test_{i}']['sep_day'] = i\n",
    "    \n",
    "### 각 데이터를 하나의 데이터로 통합\n",
    "test = pd.DataFrame()\n",
    "idx_list = []\n",
    "for i in range(81):\n",
    "    test = pd.concat([test, globals()[f'test_{i}']], axis = 0, ignore_index = True)\n",
    "    \n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Hour = train.Hour.astype('category')\n",
    "test.Hour = test.Hour.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['rainfall'] = [1 if x == 100 else 0 for x in train.RH]\n",
    "test['rainfall'] = [1 if x == 100 else 0 for x in test.RH]\n",
    "\n",
    "train.rainfall = train.rainfall.astype('category')\n",
    "test.rainfall = test.rainfall.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pb_loss(true, pred, q) :\n",
    "    \n",
    "    L_list = []\n",
    "    \n",
    "    for i in range(len(true)) :\n",
    "        \n",
    "        if true.iloc[i] >= pred[i] :\n",
    "            L = true.iloc[i] - pred[i]\n",
    "            L *= q\n",
    "            \n",
    "        else :\n",
    "            L1 = pred[i] - true.iloc[i]\n",
    "            L2 = 1 - q\n",
    "            L = L1 * L2\n",
    "            \n",
    "        L_list.append(L)\n",
    "        \n",
    "    return np.mean(L_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(data, n1, n2, is_train = None) : \n",
    "    \n",
    "    data['after_1d'] = data.shift(n1)['TARGET']\n",
    "    data['after_2d'] = data.shift(n2)['TARGET']\n",
    "    if is_train == True :\n",
    "        data.dropna(inplace = True)\n",
    "    else :\n",
    "        pass\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = make_data(train, -48, -96, is_train = True) # 1일, 2일 뒤 TARGET \n",
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 17.62\n",
    "c = 243.12\n",
    "\n",
    "gamma = (b * df_train['T'] / (c + df_train['T'])) + np.log(df_train.RH / 100)\n",
    "df_train['rh_d'] = (c * gamma) / (b - gamma)\n",
    "\n",
    "gamma = (b * df_test['T'] / (c + df_test['T'])) + np.log(df_test.RH / 100)\n",
    "df_test['rh_d'] = (c * gamma) / (b - gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['vp'] = 6.11 * 10 ** (7.5 * df_train['T'] / (df_train['T'] + 237.3))\n",
    "df_test['vp'] = 6.11 * 10 ** (7.5 * test['T'] / (test['T'] + 237.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test['sep'] = test.index // 48 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_times = []\n",
    "for day in df_train.Day.unique() :\n",
    "    d = df_train.loc[df_train.Day == day]\n",
    "    try :\n",
    "        start = d.loc[d.TARGET > 0].index[0]\n",
    "        end = d.loc[d.TARGET > 0].index[-1]\n",
    "        gap = (end - start) / 2\n",
    "    except :\n",
    "        gap = 0\n",
    "\n",
    "    tr_times.append(gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['sep'] = df_test.index // 48 # df_df_test 데이터의 경우 시계열 고려가 안되었기 때문에 48(하루 시간)으로 나눈 몫으로 day 구분자 생성\n",
    "\n",
    "\n",
    "te_times = []\n",
    "for day in df_test.sep.unique() :\n",
    "    d = df_test.loc[df_test.sep == day]\n",
    "    try :\n",
    "        start = d.loc[d.TARGET > 0].index[0]\n",
    "        end = d.loc[d.TARGET > 0].index[-1]\n",
    "        gap = (end - start) / 2\n",
    "    except :\n",
    "        gap = 0\n",
    "\n",
    "    te_times.append(gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sun_time = pd.DataFrame({'Day' : df_train.Day.unique(), 'sun_time' : tr_times})\n",
    "df_test_sun_time = pd.DataFrame({'sep' : df_test.sep.unique(), 'sun_time' : te_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_train_sun_time, how = 'left', on = 'Day')\n",
    "df_test = pd.merge(df_test, df_test_sun_time, how = 'left', on = 'sep')#.drop('sep', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sin h = (sin δ * sin φ) + (cos δ * cos φ * cos H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적위\n",
    "df_train['dos'] = [-23.44 * np.cos(360 / 365 * (x + 10)) for x in df_train.Day]\n",
    "df_test['dos'] = [-23.44 * np.cos(360 / 365 * (x + 10)) for x in df_test.sep_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간각\n",
    "df_train['high_angle'] = [(x - 12) * 15 if x >= 12 else -(12 - x) * 15 for x in df_train.Hour]\n",
    "df_test['high_angle'] = [(x - 12) * 15 if x >= 12 else -(12 - x) * 15 for x in df_test.Hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['zenith_angle'] = 90 - 1 / (np.sin(np.sin(df_train['dos']) * np.sin(36) + np.cos(df_train['dos']) *np.cos(36) * np.cos(df_train['high_angle'])))\n",
    "df_test['zenith_angle'] = 90 - 1 / (np.sin(np.sin(df_test['dos']) * np.sin(36) + np.cos(df_test['dos']) *np.cos(36) * np.cos(df_test['high_angle'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['GHI'] = np.cos(df_train.zenith_angle) * df_train.DNI + df_train.DHI\n",
    "df_test['GHI'] = np.cos(df_test.zenith_angle) * df_test.DNI + df_test.DHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_lgbm_prediction(trainx, trainy, target, n) :\n",
    "    lgbm_submission = pd.DataFrame(np.zeros((3888, 9)), columns = submission.columns[1:],\n",
    "                                   index = submission.loc[submission.id.str.contains(f'y{n}')].index)\n",
    "    \n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 114)\n",
    "\n",
    "    \n",
    "    quantile = [.09, .19, .28, .37, .48, .59, .702, .8, .9]\n",
    "    \n",
    "    total_loss = []\n",
    "    total_val_loss = []\n",
    "    \n",
    "    for i, (tr_idx, val_idx) in enumerate(kf.split(trainx, trainy)) :\n",
    "\n",
    "        print('=' * 30)\n",
    "        print(f'        {i + 1}번째 KFOLD 시작')\n",
    "\n",
    "        nfold_loss = []\n",
    "        nfold_val_loss = []\n",
    "\n",
    "        tr_X, tr_y = trainx.iloc[tr_idx], trainy.iloc[tr_idx]\n",
    "        val_X, val_y = trainx.iloc[val_idx], trainy.iloc[val_idx]\n",
    "        \n",
    "        p = 0\n",
    "        for q in quantile:\n",
    "            p += 1\n",
    "            lgbm = LGBMRegressor(random_state = 114, objective = 'quantile', metric = 'quantile', alpha = q, max_depth = 5)\n",
    "            lgbm.fit(tr_X, tr_y, eval_set = [(val_X, val_y)], eval_metric = 'quantile', early_stopping_rounds = 500, verbose = 0)\n",
    "            best_loss = float(str(lgbm.best_score_['valid_0']).split(',')[-1][1:-3])\n",
    "            print(f'{q} quantile loss = {best_loss}')\n",
    "            nfold_loss.append(best_loss)\n",
    "            \n",
    "            total_loss.append(best_loss)\n",
    "            \n",
    "            lgbm_pred = [0 if x < 0 else x for x in lgbm.predict(target) / 5]\n",
    "            lgbm_submission.iloc[:, p - 1] += lgbm_pred\n",
    "        print(f'{i + 1}번째 KFOLD 평균 loss는 {np.mean(nfold_loss)}')\n",
    "\n",
    "    print(f'\\n전체 평균 loss는 {np.mean(total_loss)}')\n",
    "    return lgbm_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['Day','Minute', 'DHI', 'RH', 'WS', 'after_1d', 'after_2d'], axis = 1)\n",
    "y1 = df_train['after_1d']\n",
    "y2 = df_train['after_2d']\n",
    "target = df_test.loc[df_test.Day == 6, X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "        1번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.2408554583650921\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.081498570109854\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.474417478168031\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.6335225503128226\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.589231708347374\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.3070683740695808\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.8534705953817074\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.3809208364633037\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.7736684191483697\n",
      "1번째 KFOLD 평균 loss는 1.9260726655962368\n",
      "==============================\n",
      "        2번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.2269804496789525\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.054898206855775\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.4426219469639627\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.622212554260185\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.590822419801225\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.333713929816436\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.86736590531883\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.371437457812523\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.7775085874032757\n",
      "2번째 KFOLD 평균 loss는 1.9208401619901296\n",
      "==============================\n",
      "        3번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.251721056323598\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.1010722759002975\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.521589071423929\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.6694607764420364\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.654621936954553\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.38346836239442\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.9208748536038962\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.4252405277150342\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.7855200265944067\n",
      "3번째 KFOLD 평균 loss는 1.9681743208169082\n",
      "==============================\n",
      "        4번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.253538627881317\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.093220835377481\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.511385360069056\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.692826160719737\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.628051847394821\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.3342495298523867\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.8761285357262416\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.386480718932732\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.7745729799048999\n",
      "4번째 KFOLD 평균 loss는 1.9500505106509634\n",
      "==============================\n",
      "        5번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.2184591718688411\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.080677972150839\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.4983273866108915\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.671005405015152\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.617006668534513\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.333983771499871\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.8694003406860449\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.3830027497308237\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.7766350297109268\n",
      "5번째 KFOLD 평균 loss는 1.938722055089767\n",
      "\n",
      "전체 평균 loss는 1.940771942828801\n"
     ]
    }
   ],
   "source": [
    "lgbm7 = kfold_lgbm_prediction(X, y1, target, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.383903</td>\n",
       "      <td>12.488317</td>\n",
       "      <td>15.507239</td>\n",
       "      <td>17.690991</td>\n",
       "      <td>19.913967</td>\n",
       "      <td>21.548179</td>\n",
       "      <td>22.844537</td>\n",
       "      <td>24.030285</td>\n",
       "      <td>25.481812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.581362</td>\n",
       "      <td>17.197816</td>\n",
       "      <td>20.984100</td>\n",
       "      <td>23.587881</td>\n",
       "      <td>26.064040</td>\n",
       "      <td>28.003682</td>\n",
       "      <td>29.469555</td>\n",
       "      <td>30.509055</td>\n",
       "      <td>31.599727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.373151</td>\n",
       "      <td>0.755870</td>\n",
       "      <td>1.094405</td>\n",
       "      <td>1.403384</td>\n",
       "      <td>1.798063</td>\n",
       "      <td>2.037886</td>\n",
       "      <td>2.567992</td>\n",
       "      <td>3.560428</td>\n",
       "      <td>4.910135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.377438</td>\n",
       "      <td>23.148404</td>\n",
       "      <td>29.346605</td>\n",
       "      <td>34.167625</td>\n",
       "      <td>39.382718</td>\n",
       "      <td>43.183939</td>\n",
       "      <td>46.070374</td>\n",
       "      <td>48.502034</td>\n",
       "      <td>51.821122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>51.671205</td>\n",
       "      <td>65.663506</td>\n",
       "      <td>77.320666</td>\n",
       "      <td>83.617651</td>\n",
       "      <td>88.583355</td>\n",
       "      <td>92.350110</td>\n",
       "      <td>94.867285</td>\n",
       "      <td>95.567873</td>\n",
       "      <td>97.080055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             q_0.1        q_0.2        q_0.3        q_0.4        q_0.5  \\\n",
       "count  3888.000000  3888.000000  3888.000000  3888.000000  3888.000000   \n",
       "mean      7.383903    12.488317    15.507239    17.690991    19.913967   \n",
       "std      10.581362    17.197816    20.984100    23.587881    26.064040   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.373151     0.755870     1.094405     1.403384     1.798063   \n",
       "75%      13.377438    23.148404    29.346605    34.167625    39.382718   \n",
       "max      51.671205    65.663506    77.320666    83.617651    88.583355   \n",
       "\n",
       "             q_0.6        q_0.7        q_0.8        q_0.9  \n",
       "count  3888.000000  3888.000000  3888.000000  3888.000000  \n",
       "mean     21.548179    22.844537    24.030285    25.481812  \n",
       "std      28.003682    29.469555    30.509055    31.599727  \n",
       "min       0.000000     0.000000     0.001085     0.001853  \n",
       "25%       0.000203     0.000630     0.001085     0.001853  \n",
       "50%       2.037886     2.567992     3.560428     4.910135  \n",
       "75%      43.183939    46.070374    48.502034    51.821122  \n",
       "max      92.350110    94.867285    95.567873    97.080055  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm7.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "        1번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.246248865685785\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.131181800112783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.5774295088228367\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.782855105827997\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.7113123537866786\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.429346099672056\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.9695119019203848\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.4497714353484932\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.8043459840142859\n",
      "1번째 KFOLD 평균 loss는 2.0113336727990334\n",
      "==============================\n",
      "        2번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.2550080528755674\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.130717355609239\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.573773014535428\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.758998669242466\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.731352848953171\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.454634304333436\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.9621749124391108\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.4431760663168967\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.8068747371204854\n",
      "2번째 KFOLD 평균 loss는 2.0129677734917557\n",
      "==============================\n",
      "        3번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.285636942685336\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.196802228341808\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.651703065663615\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.8384948312730516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.7971006694576297\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.474944033567176\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.9856072673858436\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.4707296978712245\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.8228265502406976\n",
      "3번째 KFOLD 평균 loss는 2.05820503183182\n",
      "==============================\n",
      "        4번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.2667445439758582\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.138801045793855\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.59053845195292\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.763725426443018\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.7056759246894497\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.4302337070468742\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.9495474291542756\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.4310045364856203\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.7894731699297544\n",
      "4번째 KFOLD 평균 loss는 2.0073049150524027\n",
      "==============================\n",
      "        5번째 KFOLD 시작\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.09 quantile loss = 1.2728831650238306\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.19 quantile loss = 2.1461399507159773\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.28 quantile loss = 2.6042569666715134\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.37 quantile loss = 2.752216661814404\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.48 quantile loss = 2.6737749341225228\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.59 quantile loss = 2.389059772173404\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702 quantile loss = 1.9220619145691593\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8 quantile loss = 1.4151427830033634\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.9 quantile loss = 0.7830565711029593\n",
      "5번째 KFOLD 평균 loss는 1.995399191021904\n",
      "\n",
      "전체 평균 loss는 2.017042116839383\n"
     ]
    }
   ],
   "source": [
    "lgbm8 = kfold_lgbm_prediction(X, y2, target, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.704957</td>\n",
       "      <td>11.968263</td>\n",
       "      <td>15.337114</td>\n",
       "      <td>17.965763</td>\n",
       "      <td>20.366730</td>\n",
       "      <td>22.078626</td>\n",
       "      <td>23.384826</td>\n",
       "      <td>24.564578</td>\n",
       "      <td>25.729699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.359304</td>\n",
       "      <td>16.168969</td>\n",
       "      <td>20.335368</td>\n",
       "      <td>23.549630</td>\n",
       "      <td>26.436551</td>\n",
       "      <td>28.651058</td>\n",
       "      <td>30.165440</td>\n",
       "      <td>31.141906</td>\n",
       "      <td>31.832449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.001830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.001830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.333073</td>\n",
       "      <td>0.689778</td>\n",
       "      <td>1.029788</td>\n",
       "      <td>1.450391</td>\n",
       "      <td>1.881676</td>\n",
       "      <td>1.953209</td>\n",
       "      <td>2.591670</td>\n",
       "      <td>3.654140</td>\n",
       "      <td>5.379897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.743579</td>\n",
       "      <td>23.202345</td>\n",
       "      <td>30.655141</td>\n",
       "      <td>35.947132</td>\n",
       "      <td>41.192811</td>\n",
       "      <td>44.433936</td>\n",
       "      <td>46.863404</td>\n",
       "      <td>49.439989</td>\n",
       "      <td>52.362066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.515362</td>\n",
       "      <td>70.166436</td>\n",
       "      <td>77.985925</td>\n",
       "      <td>81.515409</td>\n",
       "      <td>85.978025</td>\n",
       "      <td>92.048038</td>\n",
       "      <td>96.787724</td>\n",
       "      <td>96.922060</td>\n",
       "      <td>97.904492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             q_0.1        q_0.2        q_0.3        q_0.4        q_0.5  \\\n",
       "count  3888.000000  3888.000000  3888.000000  3888.000000  3888.000000   \n",
       "mean      6.704957    11.968263    15.337114    17.965763    20.366730   \n",
       "std       9.359304    16.168969    20.335368    23.549630    26.436551   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.333073     0.689778     1.029788     1.450391     1.881676   \n",
       "75%      12.743579    23.202345    30.655141    35.947132    41.192811   \n",
       "max      39.515362    70.166436    77.985925    81.515409    85.978025   \n",
       "\n",
       "             q_0.6        q_0.7        q_0.8        q_0.9  \n",
       "count  3888.000000  3888.000000  3888.000000  3888.000000  \n",
       "mean     22.078626    23.384826    24.564578    25.729699  \n",
       "std      28.651058    30.165440    31.141906    31.832449  \n",
       "min       0.000000     0.000630     0.001084     0.001830  \n",
       "25%       0.000203     0.000630     0.001084     0.001830  \n",
       "50%       1.953209     2.591670     3.654140     5.379897  \n",
       "75%      44.433936    46.863404    49.439989    52.362066  \n",
       "max      92.048038    96.787724    96.922060    97.904492  "
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm8.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_gb_prediction(trainx, trainy, target, n) :\n",
    "    gb_submission = pd.DataFrame(np.zeros((3888, 9)), columns = submission.columns[1:],\n",
    "                                   index = submission.loc[submission.id.str.contains(f'y{n}')].index)\n",
    "    \n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 114)\n",
    "\n",
    "    \n",
    "    quantile = [.09, .19, .28, .37, .48, .59, .702, .8, .9]\n",
    "    \n",
    "    total_loss = []\n",
    "    total_val_loss = []\n",
    "    \n",
    "    for i, (tr_idx, val_idx) in enumerate(kf.split(trainx, trainy)) :\n",
    "\n",
    "        print('=' * 30)\n",
    "        print(f'        {i + 1}번째 KFOLD 시작')\n",
    "\n",
    "        nfold_loss = []\n",
    "        nfold_val_loss = []\n",
    "\n",
    "        tr_X, tr_y = trainx.iloc[tr_idx], trainy.iloc[tr_idx]\n",
    "        val_X, val_y = trainx.iloc[val_idx], trainy.iloc[val_idx]\n",
    "        \n",
    "        p = 0\n",
    "        for q in quantile:\n",
    "            p += 1\n",
    "            gb = GradientBoostingRegressor(random_state = 114, loss = 'quantile', alpha = q, max_depth = 5)\n",
    "            gb.fit(tr_X, tr_y)\n",
    "            pred = gb.predict(val_X)\n",
    "            best_loss = pb_loss(val_y, pred, q)\n",
    "            print(f'{q} quantile loss = {best_loss}')\n",
    "            nfold_loss.append(best_loss)\n",
    "            \n",
    "            total_loss.append(best_loss)\n",
    "            \n",
    "            gb_pred = [0 if x < 0 else x for x in gb.predict(target) / 5]\n",
    "            gb_submission.iloc[:, p - 1] += gb_pred\n",
    "        print(f'{i + 1}번째 KFOLD 평균 loss는 {np.mean(nfold_loss)}')\n",
    "\n",
    "    print(f'전체 평균 loss는 {np.mean(total_loss)}')\n",
    "    return gb_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "        1번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.2536774353615585\n",
      "0.19 quantile loss = 2.085299938592596\n",
      "0.28 quantile loss = 2.472886299047963\n",
      "0.37 quantile loss = 2.645550264373355\n",
      "0.48 quantile loss = 2.5878196127322086\n",
      "0.59 quantile loss = 2.3327207255549065\n",
      "0.702 quantile loss = 1.8872500548993043\n",
      "0.8 quantile loss = 1.384074359342526\n",
      "0.9 quantile loss = 0.7851315659455534\n",
      "1번째 KFOLD 평균 loss는 1.9371566950944414\n",
      "==============================\n",
      "        2번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.2583646875105876\n",
      "0.19 quantile loss = 2.0764871808695466\n",
      "0.28 quantile loss = 2.461858841135225\n",
      "0.37 quantile loss = 2.650337348524398\n",
      "0.48 quantile loss = 2.613291919281131\n",
      "0.59 quantile loss = 2.3609291223181974\n",
      "0.702 quantile loss = 1.89724995493887\n",
      "0.8 quantile loss = 1.3861140054367047\n",
      "0.9 quantile loss = 0.7990690093085426\n",
      "2번째 KFOLD 평균 loss는 1.9448557854803559\n",
      "==============================\n",
      "        3번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.272564628188334\n",
      "0.19 quantile loss = 2.115907473160399\n",
      "0.28 quantile loss = 2.5284516286320855\n",
      "0.37 quantile loss = 2.7093962272961196\n",
      "0.48 quantile loss = 2.688582024324582\n",
      "0.59 quantile loss = 2.414192945401044\n",
      "0.702 quantile loss = 1.972078963096776\n",
      "0.8 quantile loss = 1.4403449778949577\n",
      "0.9 quantile loss = 0.8086127797923979\n",
      "3번째 KFOLD 평균 loss는 1.9944590719762993\n",
      "==============================\n",
      "        4번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.277282553223641\n",
      "0.19 quantile loss = 2.1082692077817047\n",
      "0.28 quantile loss = 2.5235934022813447\n",
      "0.37 quantile loss = 2.6927259004330626\n",
      "0.48 quantile loss = 2.6590701495659426\n",
      "0.59 quantile loss = 2.3863530468632836\n",
      "0.702 quantile loss = 1.9345015966488674\n",
      "0.8 quantile loss = 1.4214734572109973\n",
      "0.9 quantile loss = 0.812967143715363\n",
      "4번째 KFOLD 평균 loss는 1.9795818286360227\n",
      "==============================\n",
      "        5번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.2393892574254084\n",
      "0.19 quantile loss = 2.0931077431088605\n",
      "0.28 quantile loss = 2.519617033043265\n",
      "0.37 quantile loss = 2.68228940393199\n",
      "0.48 quantile loss = 2.6432003074448973\n",
      "0.59 quantile loss = 2.3633902250781547\n",
      "0.702 quantile loss = 1.9029689725957315\n",
      "0.8 quantile loss = 1.3980416091663619\n",
      "0.9 quantile loss = 0.8001421256782708\n",
      "5번째 KFOLD 평균 loss는 1.9602385197192156\n",
      "전체 평균 loss는 1.9632583801812669\n"
     ]
    }
   ],
   "source": [
    "gb7 = kfold_gb_prediction(X, y1, target, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.850085</td>\n",
       "      <td>12.039928</td>\n",
       "      <td>15.074511</td>\n",
       "      <td>17.421482</td>\n",
       "      <td>19.571713</td>\n",
       "      <td>21.213387</td>\n",
       "      <td>22.376339</td>\n",
       "      <td>23.385513</td>\n",
       "      <td>24.644652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.762055</td>\n",
       "      <td>16.546899</td>\n",
       "      <td>20.420253</td>\n",
       "      <td>23.225668</td>\n",
       "      <td>25.702945</td>\n",
       "      <td>27.655589</td>\n",
       "      <td>28.988694</td>\n",
       "      <td>29.861888</td>\n",
       "      <td>30.581873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.024982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.374480</td>\n",
       "      <td>0.729088</td>\n",
       "      <td>1.006616</td>\n",
       "      <td>1.392201</td>\n",
       "      <td>1.676131</td>\n",
       "      <td>2.068385</td>\n",
       "      <td>2.520642</td>\n",
       "      <td>3.441036</td>\n",
       "      <td>5.486739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.471416</td>\n",
       "      <td>21.890322</td>\n",
       "      <td>28.151802</td>\n",
       "      <td>33.471476</td>\n",
       "      <td>38.582389</td>\n",
       "      <td>42.801154</td>\n",
       "      <td>44.442424</td>\n",
       "      <td>46.555982</td>\n",
       "      <td>49.007226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>47.890251</td>\n",
       "      <td>62.091996</td>\n",
       "      <td>75.400413</td>\n",
       "      <td>81.038544</td>\n",
       "      <td>87.414525</td>\n",
       "      <td>90.862096</td>\n",
       "      <td>93.742638</td>\n",
       "      <td>95.344668</td>\n",
       "      <td>96.405524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             q_0.1        q_0.2        q_0.3        q_0.4        q_0.5  \\\n",
       "count  3888.000000  3888.000000  3888.000000  3888.000000  3888.000000   \n",
       "mean      6.850085    12.039928    15.074511    17.421482    19.571713   \n",
       "std       9.762055    16.546899    20.420253    23.225668    25.702945   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.374480     0.729088     1.006616     1.392201     1.676131   \n",
       "75%      12.471416    21.890322    28.151802    33.471476    38.582389   \n",
       "max      47.890251    62.091996    75.400413    81.038544    87.414525   \n",
       "\n",
       "             q_0.6        q_0.7        q_0.8        q_0.9  \n",
       "count  3888.000000  3888.000000  3888.000000  3888.000000  \n",
       "mean     21.213387    22.376339    23.385513    24.644652  \n",
       "std      27.655589    28.988694    29.861888    30.581873  \n",
       "min       0.000000     0.000504     0.001085     0.001454  \n",
       "25%       0.000203     0.000630     0.001085     0.024982  \n",
       "50%       2.068385     2.520642     3.441036     5.486739  \n",
       "75%      42.801154    44.442424    46.555982    49.007226  \n",
       "max      90.862096    93.742638    95.344668    96.405524  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb7.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "        1번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.2677567241284688\n",
      "0.19 quantile loss = 2.1679683638835963\n",
      "0.28 quantile loss = 2.6113589016872103\n",
      "0.37 quantile loss = 2.791106536126418\n",
      "0.48 quantile loss = 2.739735037426501\n",
      "0.59 quantile loss = 2.4584310238106886\n",
      "0.702 quantile loss = 1.9834399209948164\n",
      "0.8 quantile loss = 1.4545575246831153\n",
      "0.9 quantile loss = 0.8252085578313323\n",
      "1번째 KFOLD 평균 loss는 2.033284732285794\n",
      "==============================\n",
      "        2번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.272054876452408\n",
      "0.19 quantile loss = 2.1698286192912573\n",
      "0.28 quantile loss = 2.615848620363\n",
      "0.37 quantile loss = 2.7980526258099867\n",
      "0.48 quantile loss = 2.7506811589622817\n",
      "0.59 quantile loss = 2.4538841744751947\n",
      "0.702 quantile loss = 1.983121238294539\n",
      "0.8 quantile loss = 1.446873736698353\n",
      "0.9 quantile loss = 0.8180900961557885\n",
      "2번째 KFOLD 평균 loss는 2.0342705718336456\n",
      "==============================\n",
      "        3번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.313433116490525\n",
      "0.19 quantile loss = 2.232283388521042\n",
      "0.28 quantile loss = 2.6761010626463837\n",
      "0.37 quantile loss = 2.861337702921491\n",
      "0.48 quantile loss = 2.8087638656359015\n",
      "0.59 quantile loss = 2.499950992495127\n",
      "0.702 quantile loss = 2.0142311732883296\n",
      "0.8 quantile loss = 1.472345778865247\n",
      "0.9 quantile loss = 0.8417410428876084\n",
      "3번째 KFOLD 평균 loss는 2.080020902639073\n",
      "==============================\n",
      "        4번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.3042462341291041\n",
      "0.19 quantile loss = 2.1958822808051184\n",
      "0.28 quantile loss = 2.6362964080859603\n",
      "0.37 quantile loss = 2.7914958906929397\n",
      "0.48 quantile loss = 2.726564205834261\n",
      "0.59 quantile loss = 2.453943639191524\n",
      "0.702 quantile loss = 1.9841322710135603\n",
      "0.8 quantile loss = 1.4467648803035422\n",
      "0.9 quantile loss = 0.8275377934560992\n",
      "4번째 KFOLD 평균 loss는 2.0407626226124567\n",
      "==============================\n",
      "        5번째 KFOLD 시작\n",
      "0.09 quantile loss = 1.2851953436559986\n",
      "0.19 quantile loss = 2.183876380263371\n",
      "0.28 quantile loss = 2.5939601936165357\n",
      "0.37 quantile loss = 2.7703565155930385\n",
      "0.48 quantile loss = 2.699842746809209\n",
      "0.59 quantile loss = 2.4064627500715\n",
      "0.702 quantile loss = 1.9332182891537564\n",
      "0.8 quantile loss = 1.4094507028669816\n",
      "0.9 quantile loss = 0.7949542255582708\n",
      "5번째 KFOLD 평균 loss는 2.008590794176518\n",
      "전체 평균 loss는 2.039385924709497\n"
     ]
    }
   ],
   "source": [
    "gb8 = kfold_gb_prediction(X, y2, target, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "      <td>3888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.100035</td>\n",
       "      <td>11.327073</td>\n",
       "      <td>14.854631</td>\n",
       "      <td>17.484043</td>\n",
       "      <td>19.915861</td>\n",
       "      <td>21.539918</td>\n",
       "      <td>22.732707</td>\n",
       "      <td>23.678941</td>\n",
       "      <td>24.930509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.399600</td>\n",
       "      <td>15.150717</td>\n",
       "      <td>19.634915</td>\n",
       "      <td>22.889013</td>\n",
       "      <td>25.862462</td>\n",
       "      <td>27.973073</td>\n",
       "      <td>29.334562</td>\n",
       "      <td>30.153629</td>\n",
       "      <td>30.784903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.020120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.229303</td>\n",
       "      <td>0.647852</td>\n",
       "      <td>1.181871</td>\n",
       "      <td>1.561115</td>\n",
       "      <td>2.002067</td>\n",
       "      <td>2.162515</td>\n",
       "      <td>2.614363</td>\n",
       "      <td>3.770801</td>\n",
       "      <td>5.846680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.567607</td>\n",
       "      <td>22.122552</td>\n",
       "      <td>29.611817</td>\n",
       "      <td>35.209484</td>\n",
       "      <td>40.217151</td>\n",
       "      <td>43.319700</td>\n",
       "      <td>45.472078</td>\n",
       "      <td>46.634440</td>\n",
       "      <td>49.375641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.978671</td>\n",
       "      <td>58.168114</td>\n",
       "      <td>69.938865</td>\n",
       "      <td>76.580296</td>\n",
       "      <td>84.510558</td>\n",
       "      <td>92.228101</td>\n",
       "      <td>94.986842</td>\n",
       "      <td>96.268382</td>\n",
       "      <td>96.534592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             q_0.1        q_0.2        q_0.3        q_0.4        q_0.5  \\\n",
       "count  3888.000000  3888.000000  3888.000000  3888.000000  3888.000000   \n",
       "mean      6.100035    11.327073    14.854631    17.484043    19.915861   \n",
       "std       8.399600    15.150717    19.634915    22.889013    25.862462   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.229303     0.647852     1.181871     1.561115     2.002067   \n",
       "75%      11.567607    22.122552    29.611817    35.209484    40.217151   \n",
       "max      31.978671    58.168114    69.938865    76.580296    84.510558   \n",
       "\n",
       "             q_0.6        q_0.7        q_0.8        q_0.9  \n",
       "count  3888.000000  3888.000000  3888.000000  3888.000000  \n",
       "mean     21.539918    22.732707    23.678941    24.930509  \n",
       "std      27.973073    29.334562    30.153629    30.784903  \n",
       "min       0.000203     0.000630     0.001084     0.001210  \n",
       "25%       0.000203     0.000630     0.001084     0.020120  \n",
       "50%       2.162515     2.614363     3.770801     5.846680  \n",
       "75%      43.319700    45.472078    46.634440    49.375641  \n",
       "max      92.228101    94.986842    96.268382    96.534592  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb8.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission.id.str.contains('y7'), submission.columns[1:]] = lgbm7 * .6 + gb7 * .4\n",
    "submission.loc[submission.id.str.contains('y8'), submission.columns[1:]] = lgbm8 * .7 + gb8 * .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission.id.str.contains('_0h|_1h|_2h|_3h|_4h|20h|21h|22h|23h'), submission.columns[1:]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7776.000000</td>\n",
       "      <td>7776.000000</td>\n",
       "      <td>7776.000000</td>\n",
       "      <td>7776.000000</td>\n",
       "      <td>7776.000000</td>\n",
       "      <td>7776.000000</td>\n",
       "      <td>7776.000000</td>\n",
       "      <td>7776.000000</td>\n",
       "      <td>7776.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.843210</td>\n",
       "      <td>12.035924</td>\n",
       "      <td>15.253489</td>\n",
       "      <td>17.691248</td>\n",
       "      <td>19.990830</td>\n",
       "      <td>21.653988</td>\n",
       "      <td>22.913723</td>\n",
       "      <td>24.019642</td>\n",
       "      <td>25.290390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.667841</td>\n",
       "      <td>16.398367</td>\n",
       "      <td>20.431927</td>\n",
       "      <td>23.391769</td>\n",
       "      <td>26.088867</td>\n",
       "      <td>28.152849</td>\n",
       "      <td>29.587875</td>\n",
       "      <td>30.534757</td>\n",
       "      <td>31.342747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.318213</td>\n",
       "      <td>0.700802</td>\n",
       "      <td>1.055926</td>\n",
       "      <td>1.441081</td>\n",
       "      <td>1.800563</td>\n",
       "      <td>1.995584</td>\n",
       "      <td>2.588545</td>\n",
       "      <td>3.403086</td>\n",
       "      <td>4.866488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.689828</td>\n",
       "      <td>22.605776</td>\n",
       "      <td>29.712476</td>\n",
       "      <td>34.892230</td>\n",
       "      <td>39.975393</td>\n",
       "      <td>43.528900</td>\n",
       "      <td>45.824446</td>\n",
       "      <td>48.031452</td>\n",
       "      <td>51.001846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.182281</td>\n",
       "      <td>66.506196</td>\n",
       "      <td>76.494094</td>\n",
       "      <td>82.372939</td>\n",
       "      <td>87.837835</td>\n",
       "      <td>92.102057</td>\n",
       "      <td>95.661796</td>\n",
       "      <td>95.872497</td>\n",
       "      <td>96.498077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             q_0.1        q_0.2        q_0.3        q_0.4        q_0.5  \\\n",
       "count  7776.000000  7776.000000  7776.000000  7776.000000  7776.000000   \n",
       "mean      6.843210    12.035924    15.253489    17.691248    19.990830   \n",
       "std       9.667841    16.398367    20.431927    23.391769    26.088867   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.318213     0.700802     1.055926     1.441081     1.800563   \n",
       "75%      12.689828    22.605776    29.712476    34.892230    39.975393   \n",
       "max      49.182281    66.506196    76.494094    82.372939    87.837835   \n",
       "\n",
       "             q_0.6        q_0.7        q_0.8        q_0.9  \n",
       "count  7776.000000  7776.000000  7776.000000  7776.000000  \n",
       "mean     21.653988    22.913723    24.019642    25.290390  \n",
       "std      28.152849    29.587875    30.534757    31.342747  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       1.995584     2.588545     3.403086     4.866488  \n",
       "75%      43.528900    45.824446    48.031452    51.001846  \n",
       "max      92.102057    95.661796    95.872497    96.498077  "
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = datetime.datetime.strftime(datetime.datetime.today(),'%Y%m%d_%H%M%S')\n",
    "submission.to_csv(f'sun_{time_str}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM만 했을 때 1.86199"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
