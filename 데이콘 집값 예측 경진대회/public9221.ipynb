{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c809ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from ngboost import NGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f33c71",
   "metadata": {},
   "source": [
    "- id : 데이터 고유 id\n",
    "- OverallQual : 전반적 재료와 마감 품질\n",
    "- YearBuilt : 완공 연도\n",
    "- YearRemodAdd : 리모델링 연도\n",
    "- ExterQual : 외관 재료 품질\n",
    "- BsmtQual : 지하실 높이\n",
    "- TotalBsmtSF : 지하실 면적 \n",
    "- 1stFlrSF : 1층 면적 \n",
    "- GrLivArea : 지상층 생활 면적\n",
    "- FullBath : 지상층 화장실 개수 \n",
    "- KitchenQual : 부억 품질 \n",
    "- GarageYrBlt : 차고 완공 연도\n",
    "- GarageCars: 차고 자리 개수\n",
    "- GarageArea: 차고 면적 \n",
    "- target : 집값(달러 단위)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d68719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df461db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:, 1:]\n",
    "test = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1f6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Garage Yr Blt'] < 2050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new1'] = 2022 - train['Year Remod/Add']\n",
    "test['new1'] = 2022 - test['Year Remod/Add']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0699dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new2'] = np.log1p(train['1st Flr SF'] / train['Total Bsmt SF'])\n",
    "test['new2'] = np.log1p(test['1st Flr SF'] / test['Total Bsmt SF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bc913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new3'] = train['Gr Liv Area'] / train['1st Flr SF']\n",
    "test['new3'] = test['Gr Liv Area'] / test['1st Flr SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee12ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EQ'] = train['Exter Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})\n",
    "test['EQ'] = test['Exter Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd035b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['KQ'] = train['Kitchen Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})\n",
    "test['KQ'] = test['Kitchen Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2955a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BQ'] = train['Bsmt Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})\n",
    "test['BQ'] = test['Bsmt Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d224c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TQ'] = train['Overall Qual'] * 0.5 + train['EQ'] * 0.3 + train['KQ'] * 0.15 + train['BQ'] * 0.05\n",
    "test['TQ'] = test['Overall Qual'] * 0.5 + test['EQ'] * 0.3 + test['KQ'] * 0.15 + test['BQ'] * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a858111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "590ff879",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols :\n",
    "    ord_df = train.groupby(c).target.median().reset_index(name = f'ord_{c}')\n",
    "    train = pd.merge(train, ord_df, how = 'left')\n",
    "    test = pd.merge(test, ord_df, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e79d8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(cat_cols, axis = 1, inplace = True)\n",
    "test.drop(cat_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ef064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['KQ', 'EQ', 'BQ', 'Overall Qual', 'Garage Area', '1st Flr SF', 'target'], axis = 1)\n",
    "y = np.log1p(train.target)\n",
    "\n",
    "target = test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb60e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.fillna(target.median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec2714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7a6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMAE(true, pred) -> float:\n",
    "    mae = np.mean(np.abs(true - pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e3d9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### 1 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.08597747959431033\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.0816727872223358\n",
      "CatBoostRegressor Training Completed...NMAE = 0.08729140831662417\n",
      "NGBRegressor Training Completed...NMAE = 0.08769185484169245\n",
      "XGBRegressor Training Completed...NMAE = 0.092200131779733\n",
      "StackingRegressor Training Completed...NMAE = 0.08245985923634976\n",
      "\n",
      "********** When Ensemble, 1 FOLD Validation NMAE = 0.08268431096217665 **********\n",
      "\n",
      "##### 2 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.10898335612979533\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10155448019532137\n",
      "CatBoostRegressor Training Completed...NMAE = 0.1030231327287978\n",
      "NGBRegressor Training Completed...NMAE = 0.10275930920027265\n",
      "XGBRegressor Training Completed...NMAE = 0.11461251601968098\n",
      "StackingRegressor Training Completed...NMAE = 0.09998002010186245\n",
      "\n",
      "********** When Ensemble, 2 FOLD Validation NMAE = 0.1024944841271359 **********\n",
      "\n",
      "##### 3 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.08887969606821369\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.0885421081684602\n",
      "CatBoostRegressor Training Completed...NMAE = 0.11278282530152925\n",
      "NGBRegressor Training Completed...NMAE = 0.08605707619369075\n",
      "XGBRegressor Training Completed...NMAE = 0.09150727631055941\n",
      "StackingRegressor Training Completed...NMAE = 0.08275467570050782\n",
      "\n",
      "********** When Ensemble, 3 FOLD Validation NMAE = 0.08503281644037212 **********\n",
      "\n",
      "##### 4 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.10532939916386991\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10433732973500758\n",
      "CatBoostRegressor Training Completed...NMAE = 0.09879661286744518\n",
      "NGBRegressor Training Completed...NMAE = 0.10457391796065084\n",
      "XGBRegressor Training Completed...NMAE = 0.10999918720291087\n",
      "StackingRegressor Training Completed...NMAE = 0.09952431749941339\n",
      "\n",
      "********** When Ensemble, 4 FOLD Validation NMAE = 0.10138893292641012 **********\n",
      "\n",
      "##### 5 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.09719224809723932\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10740758926405139\n",
      "CatBoostRegressor Training Completed...NMAE = 0.09786734007273663\n",
      "NGBRegressor Training Completed...NMAE = 0.09740814834419949\n",
      "XGBRegressor Training Completed...NMAE = 0.0993007926818826\n",
      "StackingRegressor Training Completed...NMAE = 0.09660054040600274\n",
      "\n",
      "********** When Ensemble, 5 FOLD Validation NMAE = 0.09562676378531701 **********\n",
      "\n",
      "##### 6 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.09473849486268636\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10112937305471612\n",
      "CatBoostRegressor Training Completed...NMAE = 0.09220828083676144\n",
      "NGBRegressor Training Completed...NMAE = 0.09749571734682252\n",
      "XGBRegressor Training Completed...NMAE = 0.09406405606822509\n",
      "StackingRegressor Training Completed...NMAE = 0.09586562396123914\n",
      "\n",
      "********** When Ensemble, 6 FOLD Validation NMAE = 0.09316541225799835 **********\n",
      "\n",
      "##### 7 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.08715411292234489\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.08847803764715087\n",
      "CatBoostRegressor Training Completed...NMAE = 0.09055249170761036\n",
      "NGBRegressor Training Completed...NMAE = 0.08589688811298704\n",
      "XGBRegressor Training Completed...NMAE = 0.0881859756765165\n",
      "StackingRegressor Training Completed...NMAE = 0.088286157232301\n",
      "\n",
      "********** When Ensemble, 7 FOLD Validation NMAE = 0.08409030947691966 **********\n",
      "\n",
      "##### 8 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.09410664524362598\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10401514972069964\n",
      "CatBoostRegressor Training Completed...NMAE = 0.11812283500939413\n",
      "NGBRegressor Training Completed...NMAE = 0.09817577234898832\n",
      "XGBRegressor Training Completed...NMAE = 0.10180271384355019\n",
      "StackingRegressor Training Completed...NMAE = 0.09246105742335742\n",
      "\n",
      "********** When Ensemble, 8 FOLD Validation NMAE = 0.09356421304883794 **********\n",
      "\n",
      "##### 9 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.0981030318796841\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10865811426169297\n",
      "CatBoostRegressor Training Completed...NMAE = 0.11717998510469427\n",
      "NGBRegressor Training Completed...NMAE = 0.1078677886407097\n",
      "XGBRegressor Training Completed...NMAE = 0.09935268887517039\n",
      "StackingRegressor Training Completed...NMAE = 0.0978979486663374\n",
      "\n",
      "********** When Ensemble, 9 FOLD Validation NMAE = 0.10042018547222183 **********\n",
      "\n",
      "##### 10 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.10202238950302732\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.09160271248840564\n",
      "CatBoostRegressor Training Completed...NMAE = 0.09367222791800159\n",
      "NGBRegressor Training Completed...NMAE = 0.09659526086787257\n",
      "XGBRegressor Training Completed...NMAE = 0.09932266114425671\n",
      "StackingRegressor Training Completed...NMAE = 0.09284244124276018\n",
      "\n",
      "********** When Ensemble, 10 FOLD Validation NMAE = 0.09360635685799772 **********\n",
      "\n",
      "*-*-*-*-*-*-*-*-*-Training & Prediction Done.....-*-*-*-*-*-*-*-*-*\n",
      "Result : 10 FOLD Mean of NMAE = 0.09320737853553873 & std = 0.006870471686674818\n",
      "##### Average NMAE of Each Model #####\n",
      "RandomForestRegressor = 0.0962486853464797\n",
      "CatBoostRegressor = 0.1011497139863595\n",
      "NGBRegressor = 0.09645217338578863\n",
      "GradientBoostingRegressor = 0.09773976817578414\n",
      "XGBRegressor = 0.09903479996024857\n",
      "StackingRegressor = 0.09286726414701313\n"
     ]
    }
   ],
   "source": [
    "val_nmae = []\n",
    "rf_nmae = []\n",
    "ngb_nmae = []\n",
    "xgb_nmae = []\n",
    "cb_nmae = []\n",
    "gbr_nmae = []\n",
    "sr_nmae = []\n",
    "fold_pred = np.zeros(target.shape[0])\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'##### {n + 1} FOLD Training..... #####')\n",
    "    \n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    tr_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    target_data = Pool(data = target, label = None)\n",
    "    \n",
    "    ### Setting the 6models\n",
    "    rf = RandomForestRegressor(random_state = 2022, criterion = 'mae')\n",
    "    cb = CatBoostRegressor(depth = 4, random_state = 2, loss_function = 'MAE', n_estimators = 3000, learning_rate = 0.03, verbose = 0)\n",
    "    ngb = NGBRegressor(random_state = 1, n_estimators = 3000, verbose = 0, learning_rate = 0.03)\n",
    "    xgb = XGBRegressor(random_state = 28, max_depth = 4, n_estimators = 3000, learning_rate = 0.03, objective = 'reg:squarederror')\n",
    "    gbr = GradientBoostingRegressor(random_state = 67, max_depth = 4, learning_rate = 0.03, n_estimators = 1500)\n",
    "    lgbm = LGBMRegressor(random_state = 42, max_depth = 4, n_estimators = 2000, learning_rate = 0.03, objective = 'l1')\n",
    "    rg = Ridge(random_state = 203)\n",
    "    \n",
    "    ### RandomForest\n",
    "    rf.fit(tr_x, tr_y)\n",
    "    rf_val = np.expm1(rf.predict(val_x))\n",
    "    rf_score = NMAE(val_y, rf_val)\n",
    "    rf_nmae.append(rf_score)\n",
    "    print(f'{rf.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, rf_val)}')\n",
    "    \n",
    "    ### GradientBoosting\n",
    "    gbr.fit(tr_x, tr_y)\n",
    "    gbr_val = np.expm1(gbr.predict(val_x))\n",
    "    gbr_score = NMAE(val_y, gbr_val)\n",
    "    gbr_nmae.append(gbr_score)\n",
    "    print(f'{gbr.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, gbr_val)}')\n",
    "    \n",
    "    ### CatBoost\n",
    "    cb.fit(tr_data, eval_set = val_data, early_stopping_rounds = 750, verbose = 0)\n",
    "    cb_val = np.expm1(cb.predict(val_data))\n",
    "    cb_score = NMAE(val_y, cb_val)\n",
    "    cb_nmae.append(cb_score)\n",
    "    print(f'{cb.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, cb_val)}')\n",
    "    \n",
    "    ### NGBoost\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 500)\n",
    "    ngb_val = np.expm1(ngb.predict(val_x))\n",
    "    ngb_score = NMAE(val_y, ngb_val)\n",
    "    ngb_nmae.append(ngb_score)\n",
    "    print(f'{ngb.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, ngb_val)}')\n",
    "    \n",
    "    ### XGBoost\n",
    "    xgb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 500, verbose = 0, eval_metric = 'mae')\n",
    "    xgb_val = np.expm1(xgb.predict(val_x))\n",
    "    xgb_score = NMAE(val_y, xgb_val)\n",
    "    xgb_nmae.append(xgb_score)\n",
    "    print(f'{xgb.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, xgb_val)}')\n",
    "    \n",
    "    ### Stacking\n",
    "    sr = StackingRegressor(estimators = [('RF', rf), ('CB', cb), ('XGB', xgb), ('GBR', gbr), ('LGBM', lgbm)], final_estimator = rg)\n",
    "    sr.fit(tr_x, tr_y)\n",
    "    sr_val = np.expm1(sr.predict(val_x))\n",
    "    sr_score = NMAE(val_y, sr_val)\n",
    "    sr_nmae.append(sr_score)\n",
    "    print(f'{sr.__class__.__name__} Training Completed...NMAE = {sr_score}\\n')\n",
    "    \n",
    "    ### Make ensemble for validation\n",
    "    val_pred = (sr_val + rf_val + ngb_val + cb_val + xgb_val + gbr_val) / n_models\n",
    "    fold_nmae = NMAE(val_y, val_pred)\n",
    "    val_nmae.append(fold_nmae)\n",
    "    print(f'********** When Ensemble, {n + 1} FOLD Validation NMAE = {fold_nmae} **********\\n')\n",
    "    \n",
    "    ### Prediction\n",
    "    rf_fold = rf.predict(target) / (n_models * kf.n_splits)\n",
    "    cb_fold = cb.predict(target_data) / (n_models * kf.n_splits)\n",
    "    ngb_fold = ngb.predict(target) / (n_models * kf.n_splits)\n",
    "    xgb_fold = xgb.predict(target) / (n_models * kf.n_splits)\n",
    "    gbr_fold = gbr.predict(target) / (n_models * kf.n_splits)\n",
    "    sr_fold = sr.predict(target) / (n_models * kf.n_splits)\n",
    "    \n",
    "    ### Make ensemble for prediction using test data\n",
    "    fold_pred += (sr_fold + gbr_fold + rf_fold  + cb_fold + ngb_fold + xgb_fold)\n",
    "    \n",
    "print(f'*-*-*-*-*-*-*-*-*-Training & Prediction Done.....-*-*-*-*-*-*-*-*-*')\n",
    "print(f'Result : {kf.n_splits} FOLD Mean of NMAE = {np.mean(val_nmae)} & std = {np.std(val_nmae)}')\n",
    "print(f'##### Average NMAE of Each Model #####')\n",
    "print(f'{rf.__class__.__name__} = {np.mean(rf_nmae)}')\n",
    "print(f'{cb.__class__.__name__} = {np.mean(cb_nmae)}')\n",
    "print(f'{ngb.__class__.__name__} = {np.mean(ngb_nmae)}')\n",
    "print(f'{gbr.__class__.__name__} = {np.mean(gbr_nmae)}')\n",
    "print(f'{xgb.__class__.__name__} = {np.mean(xgb_nmae)}')\n",
    "print(f'{sr.__class__.__name__} = {np.mean(sr_nmae)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31d1a281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final = (sr_fold + rf_fold + xgb_fold + ngb_fold + cb_fold + gbr_fold) / n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41ae54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = np.expm1(fold_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cfe3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('202.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82df4194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>323236.829183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>128437.767121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>178251.951373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>240479.418354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>132804.182141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1346</td>\n",
       "      <td>332599.856086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1347</td>\n",
       "      <td>127051.374408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1348</td>\n",
       "      <td>72557.806444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1349</td>\n",
       "      <td>184304.263729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1350</td>\n",
       "      <td>131537.054193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         target\n",
       "0        1  323236.829183\n",
       "1        2  128437.767121\n",
       "2        3  178251.951373\n",
       "3        4  240479.418354\n",
       "4        5  132804.182141\n",
       "...    ...            ...\n",
       "1345  1346  332599.856086\n",
       "1346  1347  127051.374408\n",
       "1347  1348   72557.806444\n",
       "1348  1349  184304.263729\n",
       "1349  1350  131537.054193\n",
       "\n",
       "[1350 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
