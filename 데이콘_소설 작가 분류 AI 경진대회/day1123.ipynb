{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day1123.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmS2RYkJTNmq3IVR7Ny+xx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxqOHF9ihwG5",
        "outputId": "8293d244-3cdf-4c12-ab47-28a6e1541ca4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9twYuIWiFqs",
        "outputId": "a71ee1c4-0ba0-4c5d-8d34-193aa3751fe7"
      },
      "source": [
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,  ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import *\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "gc.collect()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "152rb5ddic1m",
        "outputId": "82670148-8f82-4ba3-e10d-efc082553430"
      },
      "source": [
        "cd /content/gdrive/My Drive/dacon/lyrics"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/dacon/lyrics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYx5MGi9idxe"
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test_x.csv\")\n",
        "submission = pd.read_csv(\"sample_submission.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1i7vvsQihWv"
      },
      "source": [
        "train.text = train.text.str.lower()\n",
        "test.text = test.text.str.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzjjnG5viiZu",
        "outputId": "4c0c03a0-db48-4302-f331-50040425c088"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BCBZR9TijZ1"
      },
      "source": [
        "tokenizer = RegexpTokenizer('\\s+', gaps = True)\n",
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zxP-ddVikwR"
      },
      "source": [
        "clear_punc = []\n",
        "for t in range(len(train.text)):\n",
        "  clear_punc.append(re.sub('[!@#$%^&“*()_+”=‘,./ª?\\><;\":`~]', ' ' ,train.text[t]))\n",
        "train['clear_punc'] = clear_punc"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoTbm4XXilZ_"
      },
      "source": [
        "clear_punc = []\n",
        "for t in range(len(test.text)):\n",
        "  clear_punc.append(re.sub('[!@#$%“^&*()_+=,‘./ª?\\><;\":`~]', ' ' ,test.text[t]))\n",
        "test['clear_punc'] = clear_punc"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtr6BCOBimSp"
      },
      "source": [
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stopwords:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIZ319lUintW"
      },
      "source": [
        "train['length_text'] = train.clear_punc.apply(lambda x : len(x))\n",
        "test['length_text'] = test.clear_punc.apply(lambda x : len(x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BIXfNVgipO_"
      },
      "source": [
        "def expand_contractions(tweet):\n",
        "    tweet = re.sub(r\"i’m\", \"i am\", tweet)\n",
        "    tweet = re.sub(r\"i’d\", \"i would\", tweet) \n",
        "    tweet = re.sub(r\"i’ll\", \"i will\", tweet)\n",
        "    tweet = re.sub(r\"i’ve\", \"i have\", tweet)\n",
        "    tweet = re.sub(r\"you’re\", \"you are\", tweet)\n",
        "    tweet = re.sub(r\"you’d\", \"you would\", tweet)\n",
        "    tweet = re.sub(r\"you’ve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you’ll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"y’know\", \"you know\", tweet)  \n",
        "    tweet = re.sub(r\"y’all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"we’re\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"we’ve\", \"we have\", tweet) \n",
        "    tweet = re.sub(r\"we’d\", \"we would\", tweet)\n",
        "    tweet = re.sub(r\"we’ll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"they’re\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"they’d\", \"they would\", tweet)\n",
        "    tweet = re.sub(r\"they’ve\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"they’ll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"he’s\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"he’ll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"she’s\", \"she is\", tweet)\n",
        "    tweet = re.sub(r\"she’ll\", \"she will\", tweet)\n",
        "    tweet = re.sub(r\"it’s\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"it’ll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"isn’t\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"who’s\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"what’s\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"that’s\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"here’s\", \"here is\", tweet)\n",
        "    tweet = re.sub(r\"there’s\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"where’s\", \"where is\", tweet) \n",
        "    tweet = re.sub(r\"how’s\", \"how is\", tweet)   \n",
        "    tweet = re.sub(r\"how’re\", \"how are\", tweet)  \n",
        "    tweet = re.sub(r\"let’s\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"won’t\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"wasn’t\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"aren’t\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"couldn’t\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"shouldn’t\", \"should not\", tweet)\n",
        "    tweet = re.sub(r\"haven’t\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"hasn’t\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"wouldn’t\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"weren’t\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"ain’t\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"don’t\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"didn’t\", \"did not\", tweet)\n",
        "    tweet = re.sub(r\"doesn’t\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"can’t\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"should’ve\", \"should have\", tweet)\n",
        "    tweet = re.sub(r\"would’ve\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
        "    tweet = re.sub(\"i've\", 'i have', tweet)\n",
        "    tweet = re.sub(\"i'd\", 'i had', tweet)\n",
        "    return tweet"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1jtZgTmiqVh"
      },
      "source": [
        "train['clear_punc'] = train.clear_punc.apply(expand_contractions)\n",
        "test['clear_punc'] = test.clear_punc.apply(expand_contractions)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZBdHIEqirLG"
      },
      "source": [
        "train.clear_punc = train.clear_punc.str.replace('-', ' ')\n",
        "train.clear_punc = train.clear_punc.str.replace(\"'\", '')\n",
        "train.clear_punc = train.clear_punc.str.replace(\"’\", '')\n",
        "train.clear_punc = train.clear_punc.str.replace(\"’\", '')\n",
        "test.clear_punc = test.clear_punc.str.replace('-', ' ')\n",
        "test.clear_punc = test.clear_punc.str.replace(\"'\", '')\n",
        "test.clear_punc = test.clear_punc.str.replace(\"’\", '')\n",
        "test.clear_punc = test.clear_punc.str.replace(\"’\", '')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbKjTaVIir5H"
      },
      "source": [
        "train.clear_punc = train.clear_punc.str.replace(\"’\", '')\n",
        "train.clear_punc = train.clear_punc.str.replace(\"’\", '')\n",
        "train.clear_punc = train.clear_punc.str.replace(\"—\", ' ')\n",
        "train.clear_punc = train.clear_punc.str.replace(\"”\", ' ')\n",
        "test.clear_punc = test.clear_punc.str.replace(\"’\", '')\n",
        "test.clear_punc = test.clear_punc.str.replace(\"’\", '')\n",
        "test.clear_punc = test.clear_punc.str.replace(\"—\", ' ')\n",
        "test.clear_punc = test.clear_punc.str.replace(\"”\", ' ')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_aIVX6hisp1"
      },
      "source": [
        "#train.clear_punc = train.clear_punc.apply(remove_stopwords)\n",
        "#test.clear_punc = test.clear_punc.apply(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vijM-1diu2m"
      },
      "source": [
        "token_text = []\n",
        "\n",
        "for t in train.clear_punc:\n",
        "  temp = tokenizer.tokenize(t)\n",
        "  #temp = [word for word in temp if not word in stopwords]\n",
        "  token_text.append(temp)\n",
        "\n",
        "train['token_text'] = token_text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7E-T237ivua"
      },
      "source": [
        "token_text = []\n",
        "\n",
        "for t in test.clear_punc:\n",
        "  temp = tokenizer.tokenize(t)\n",
        "  #temp = [word for word in temp if not word in stopwords]\n",
        "  token_text.append(temp)\n",
        "\n",
        "test['token_text'] = token_text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SH5RqiziwTq"
      },
      "source": [
        "train['length_token'] = train.token_text.apply(lambda x : len(x))\n",
        "test['length_token'] = test.token_text.apply(lambda x : len(x))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_Rw6WqjhvTic",
        "outputId": "28d4ccfe-393a-4844-9908-efffd1eb1d2a"
      },
      "source": [
        "train.length_token.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e2482d550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAREElEQVR4nO3df6zddX3H8edrVH6Ik5/mhrTNirHRoJ3KbqCGZbmBDQoYyx9oMESK6dY/hg6XJq7sjzVTSTCZIiSTrJFOMEZENKEBN9YVTpb9wU9h/OoIVyzSBqjagqtO53Xv/XE+Zae9t6X3nNt7bnufj+Tkfr/v7+f7PZ/zbpPX/X7P95ybqkKSNL/9zrAnIEkaPsNAkmQYSJIMA0kShoEkCVgw7An06/TTT68lS5YMexpD8Ytf/IITTzxx2NOYU+zJvuzHZPYEHnvssZ9W1Tum2nbEhsGSJUt49NFHhz2Noeh0OoyNjQ17GnOKPdmX/ZjMnkCSFw+0zctEkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEniCP4E8iCWrLt3KM+77YZLh/K8kvRmPDOQJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkcQhhkGRjkp1Jnu6pnZpkc5Ln289TWj1Jbk4ynuTJJGf37LOqjX8+yaqe+h8keartc3OSzPSLlCQd3KGcGXwdWLFfbR2wpaqWAlvaOsDFwNL2WAPcAt3wANYD5wLnAOv3Bkgb82c9++3/XJKkw+xNw6Cq/g3YtV95JXBbW74NuKynfnt1PQicnOQM4CJgc1XtqqrdwGZgRdv29qp6sKoKuL3nWJKkWbKgz/1GqurltvwKMNKWFwIv9Yzb3moHq2+foj6lJGvonnEwMjJCp9Ppa/Jrl030td+g+p3v/vbs2TNjxzpa2JN92Y/J7MnB9RsGb6iqSlIzMZlDeK4NwAaA0dHRGhsb6+s4V6+7dwZndei2XTk2I8fpdDr0+9qPVvZkX/ZjMntycP3eTfRqu8RD+7mz1XcAi3vGLWq1g9UXTVGXJM2ifsNgE7D3jqBVwN099avaXUXLgdfb5aT7gAuTnNLeOL4QuK9t+3mS5e0uoqt6jiVJmiVvepkoybeAMeD0JNvp3hV0A3BnktXAi8DH2vDvA5cA48AvgU8CVNWuJJ8HHmnjPldVe9+U/nO6dyydAPxTe0iSZtGbhkFVffwAmy6YYmwB1xzgOBuBjVPUHwXe92bzkCQdPn4CWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEgOGQZK/TPJMkqeTfCvJ8UnOTPJQkvEk305ybBt7XFsfb9uX9BznulZ/LslFg70kSdJ09R0GSRYCfwGMVtX7gGOAK4AvAjdW1buA3cDqtstqYHer39jGkeSstt97gRXAV5Mc0++8JEnTN+hlogXACUkWAG8FXgbOB+5q228DLmvLK9s6bfsFSdLqd1TVr6vqR8A4cM6A85IkTcOCfnesqh1J/g74MfDfwL8AjwGvVdVEG7YdWNiWFwIvtX0nkrwOnNbqD/YcuneffSRZA6wBGBkZodPp9DX3tcsm3nzQYdDvfPe3Z8+eGTvW0cKe7Mt+TGZPDq7vMEhyCt3f6s8EXgO+Q/cyz2FTVRuADQCjo6M1NjbW13GuXnfvDM7q0G27cmxGjtPpdOj3tR+t7Mm+7Mdk9uTgBrlM9MfAj6rqJ1X1G+B7wHnAye2yEcAiYEdb3gEsBmjbTwJ+1lufYh9J0iwYJAx+DCxP8tZ27f8C4FngAeDyNmYVcHdb3tTWadvvr6pq9Sva3UZnAkuBhweYlyRpmgZ5z+ChJHcBPwAmgMfpXsK5F7gjyRda7da2y63AN5KMA7vo3kFEVT2T5E66QTIBXFNVv+13XpKk6es7DACqaj2wfr/yC0xxN1BV/Qr46AGOcz1w/SBzkST1z08gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYsAwSHJykruS/GeSrUk+lOTUJJuTPN9+ntLGJsnNScaTPJnk7J7jrGrjn0+yatAXJUmankHPDG4C/rmq3gO8H9gKrAO2VNVSYEtbB7gYWNoea4BbAJKcCqwHzgXOAdbvDRBJ0uzoOwySnAT8EXArQFX9T1W9BqwEbmvDbgMua8srgdur60Hg5CRnABcBm6tqV1XtBjYDK/qdlyRp+gY5MzgT+Anwj0keT/K1JCcCI1X1chvzCjDSlhcCL/Xsv73VDlSXJM2SBQPuezbw6ap6KMlN/P8lIQCqqpLUIBPslWQN3UtMjIyM0Ol0+jrO2mUTMzWlael3vvvbs2fPjB3raGFP9mU/JrMnBzdIGGwHtlfVQ239Lrph8GqSM6rq5XYZaGfbvgNY3LP/olbbAYztV+9M9YRVtQHYADA6OlpjY2NTDXtTV6+7t6/9BrXtyrEZOU6n06Hf1360sif7sh+T2ZOD6/syUVW9AryU5N2tdAHwLLAJ2HtH0Crg7ra8Cbiq3VW0HHi9XU66D7gwySntjeMLW02SNEsGOTMA+DTwzSTHAi8An6QbMHcmWQ28CHysjf0+cAkwDvyyjaWqdiX5PPBIG/e5qto14LwkSdMwUBhU1RPA6BSbLphibAHXHOA4G4GNg8xFktQ/P4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJGDBsCcwnyxZd++MHGftsgmunuaxtt1w6Yw8t6Sjk2cGkiTDQJI0A2GQ5Jgkjye5p62fmeShJONJvp3k2FY/rq2Pt+1Leo5xXas/l+SiQeckSZqemTgzuBbY2rP+ReDGqnoXsBtY3eqrgd2tfmMbR5KzgCuA9wIrgK8mOWYG5iVJOkQDhUGSRcClwNfaeoDzgbvakNuAy9ryyrZO235BG78SuKOqfl1VPwLGgXMGmZckaXoGvZvoK8Bngd9t66cBr1XVRFvfDixsywuBlwCqaiLJ6238QuDBnmP27rOPJGuANQAjIyN0Op2+Jr122cSbD5rDRk6Y/mvot1dHij179hz1r3E67Mdk9uTg+g6DJB8GdlbVY0nGZm5KB1ZVG4ANAKOjozU21t/TTve2zLlm7bIJvvTU9P7ptl05dngmM0d0Oh36/f9wNLIfk9mTgxvkzOA84CNJLgGOB94O3AScnGRBOztYBOxo43cAi4HtSRYAJwE/66nv1buPJGkW9P2eQVVdV1WLqmoJ3TeA76+qK4EHgMvbsFXA3W15U1unbb+/qqrVr2h3G50JLAUe7ndekqTpOxyfQP4r4I4kXwAeB25t9VuBbyQZB3bRDRCq6pkkdwLPAhPANVX128MwL0nSAcxIGFRVB+i05ReY4m6gqvoV8NED7H89cP1MzEWSNH1+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJAELhj0BzY4l6+4dyvNuu+HSoTyvpOnxzECSZBhIkgwDSRIDhEGSxUkeSPJskmeSXNvqpybZnOT59vOUVk+Sm5OMJ3kyydk9x1rVxj+fZNXgL0uSNB2DnBlMAGur6ixgOXBNkrOAdcCWqloKbGnrABcDS9tjDXALdMMDWA+cC5wDrN8bIJKk2dF3GFTVy1X1g7b8X8BWYCGwEritDbsNuKwtrwRur64HgZOTnAFcBGyuql1VtRvYDKzod16SpOmbkVtLkywBPgg8BIxU1ctt0yvASFteCLzUs9v2VjtQfarnWUP3rIKRkRE6nU5f8127bKKv/eaKkROOnNfQ77/RdO3Zs2fWnutIYD8msycHN3AYJHkb8F3gM1X18yRvbKuqSlKDPkfP8TYAGwBGR0drbGysr+NcPaR77mfK2mUTfOmpI+MjItuuHJuV5+l0OvT7/+FoZD8msycHN9DdREneQjcIvllV32vlV9vlH9rPna2+A1jcs/uiVjtQXZI0Swa5myjArcDWqvpyz6ZNwN47glYBd/fUr2p3FS0HXm+Xk+4DLkxySnvj+MJWkyTNkkGuNZwHfAJ4KskTrfbXwA3AnUlWAy8CH2vbvg9cAowDvwQ+CVBVu5J8HnikjftcVe0aYF6SpGnqOwyq6t+BHGDzBVOML+CaAxxrI7Cx37lIkgbjJ5AlSYaBJMkwkCRhGEiS8I/b6DCbrT+qs3bZxKQPE/qHdaRD55mBJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJv7VUR7HZ+sbU/fltqToSeWYgSTIMJEmGgSQJw0CShGEgScK7iaQZ511MOhJ5ZiBJMgwkSYaBJIk5FAZJViR5Lsl4knXDno8kzSdzIgySHAP8PXAxcBbw8SRnDXdWkjR/zJW7ic4BxqvqBYAkdwArgWeHOivpCNJ7F9PaZRNcPYt3NXkn05EvVTXsOZDkcmBFVf1pW/8EcG5VfWq/cWuANW313cBzszrRueN04KfDnsQcY0/2ZT8msyfwe1X1jqk2zJUzg0NSVRuADcOex7AlebSqRoc9j7nEnuzLfkxmTw5uTrxnAOwAFvesL2o1SdIsmCth8AiwNMmZSY4FrgA2DXlOkjRvzInLRFU1keRTwH3AMcDGqnpmyNOay+b9pbIp2JN92Y/J7MlBzIk3kCVJwzVXLhNJkobIMJAkGQZzUZKNSXYmebqndmqSzUmebz9PafUkubl9jceTSc4e3swPjySLkzyQ5NkkzyS5ttXnc0+OT/Jwkv9oPfnbVj8zyUPttX+73ZBBkuPa+njbvmSY8z9ckhyT5PEk97T1ed2P6TAM5qavAyv2q60DtlTVUmBLW4fuV3gsbY81wC2zNMfZNAGsraqzgOXANe3rSuZzT34NnF9V7wc+AKxIshz4InBjVb0L2A2sbuNXA7tb/cY27mh0LbC1Z32+9+PQVZWPOfgAlgBP96w/B5zRls8AnmvL/wB8fKpxR+sDuBv4E3vyxut7K/AD4Fy6n7Bd0OofAu5ry/cBH2rLC9q4DHvuM9yHRXR/KTgfuAfIfO7HdB+eGRw5Rqrq5bb8CjDSlhcCL/WM295qR6V2Ov9B4CHmeU/aJZEngJ3AZuCHwGtVNdGG9L7uN3rStr8OnDa7Mz7svgJ8Fvjftn4a87sf02IYHIGq++vMvLsnOMnbgO8Cn6mqn/dum489qarfVtUH6P5GfA7wniFPaWiSfBjYWVWPDXsuRyrD4MjxapIzANrPna0+L77KI8lb6AbBN6vqe608r3uyV1W9BjxA9zLIyUn2fpi093W/0ZO2/STgZ7M81cPpPOAjSbYBd9C9VHQT87cf02YYHDk2Aava8iq618331q9qd9AsB17vuXRyVEgS4FZga1V9uWfTfO7JO5Kc3JZPoPseyla6oXB5G7Z/T/b26nLg/nY2dVSoquuqalFVLaH7dTb3V9WVzNN+9GXYb1r4mPwAvgW8DPyG7nXO1XSvZ24Bngf+FTi1jQ3dPwz0Q+ApYHTY8z8M/fhDupeAngSeaI9L5nlPfh94vPXkaeBvWv2dwMPAOPAd4LhWP76tj7ft7xz2aziMvRkD7rEf03v4dRSSJC8TSZIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkoD/AxqXDF00AgqJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "KO37nP-RvU_W",
        "outputId": "7fd5a2aa-2161-446d-a275-ef1cf974cc05"
      },
      "source": [
        "test.length_token.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e1ddb5438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U862ywq3vY-_",
        "outputId": "f0ec1b9f-32df-4fcf-981b-d96a0d495206"
      },
      "source": [
        "test.length_token.min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXTZTAdDycGb"
      },
      "source": [
        "train2 = train"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVCrSu99ixAc"
      },
      "source": [
        "train = train.loc[train.length_token > 15]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3eeEErmivdC"
      },
      "source": [
        "train.index = range(train.shape[0])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MHkcS-mygaX",
        "outputId": "ac5ea1f8-4297-4337-e00d-965268ad3315"
      },
      "source": [
        "train.loc[train.length_token > 15].author.value_counts()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    9338\n",
              "0    8636\n",
              "2    6930\n",
              "1    5520\n",
              "4    5056\n",
              "Name: author, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP184gRRiymP",
        "outputId": "ff5fdbd1-c65e-4cb4-e08b-5ff59ff67b1b"
      },
      "source": [
        "train.author.value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    15063\n",
              "0    13235\n",
              "2    11554\n",
              "4     7805\n",
              "1     7222\n",
              "Name: author, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDNhAOTfvhsm",
        "outputId": "4b61a689-2748-4d4a-f7aa-98759e8e8e77"
      },
      "source": [
        "train.groupby('author').length_token.mean()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "author\n",
              "0    38.053721\n",
              "1    57.761423\n",
              "2    40.568201\n",
              "3    41.797252\n",
              "4    42.005381\n",
              "Name: length_token, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CULWSCGiujJ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW0dO31da46P"
      },
      "source": [
        "stopwords = ['a','an','the','am','is','are','were','was']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tn4b1iPk4tQ"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train.token_text)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S-4l8rmk43o",
        "outputId": "ff8763c2-0237-47ee-9c80-eb63dc73e753"
      },
      "source": [
        "threshold = 6\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 34206\n",
            "등장 빈도가 5번 이하인 희귀 단어의 수: 21413\n",
            "단어 집합에서 희귀 단어의 비율: 62.600128632403674\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.9721078481729615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xr0_WK_k5lW",
        "outputId": "f841b361-42c7-4fda-8d87-c99dff4b4612"
      },
      "source": [
        "vocab_size = total_cnt - rare_cnt + 1 # 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거. 0번 패딩 토큰을 고려하여 +1\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 12794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2EnBAxHk6kh"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size,oov_token = 'oov')\n",
        "tokenizer.fit_on_texts(train.token_text)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loLcsGbPk7cE"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo86-kl3k8CE",
        "outputId": "33780e7e-7118-4327-9f8f-0c8232d81a26"
      },
      "source": [
        "below_threshold_len(250, train.token_text)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 250 이하인 샘플의 비율: 98.64430665163472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vACzE2oQk9AB"
      },
      "source": [
        "y = np.array([x for x in train['author']])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvXlv4Flk-qj"
      },
      "source": [
        "max_len =  250"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6gmJEzjlAyq"
      },
      "source": [
        "seq = tokenizer.texts_to_sequences(train.token_text)\n",
        "seq = pad_sequences(seq, maxlen = max_len, padding = 'post')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx_LTFT3lBcx"
      },
      "source": [
        "target = tokenizer.texts_to_sequences(test.token_text)\n",
        "target = pad_sequences(target, maxlen = max_len, padding = 'post')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVbqM-lLlMHs"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeFKg660lMaT"
      },
      "source": [
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyZLBgVI8ceb",
        "outputId": "c451310b-818f-4fcc-ddc6-d7094944c9b9"
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size , 128, input_length = max_len))\n",
        "  model.add(Dropout(.3))\n",
        "  model.add(Conv1D(64, 5, activation = 'relu', kernel_regularizer = l2(0.001)))\n",
        "  model.add(MaxPooling1D())\n",
        "  model.add(Dropout(.3))\n",
        "  model.add(LSTM(64, dropout = .3, return_sequences=True))\n",
        "  #model.add(Flatten())\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dropout(.3))\n",
        "  #model.add(Dense(16, activation = 'relu'))\n",
        "  model.add(Dense(5, activation = 'softmax'))\n",
        "  model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 250, 128)          1637632   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 250, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 246, 64)           41024     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 123, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 123, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 123, 64)           33024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,712,005\n",
            "Trainable params: 1,712,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXjYX3JL9FCK",
        "outputId": "028be0a4-61e6-4679-be34-50fdead24f42"
      },
      "source": [
        "model.compile(optimizer = RMSprop(lr = .0005), metrics = 'accuracy', loss = 'sparse_categorical_crossentropy')\n",
        "callback_ear = [EarlyStopping(monitor = 'val_accuracy', patience = 2, mode = 'max', verbose = 1), ModelCheckpoint(filepath = '1201_1.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max',verbose = 1)]\n",
        "model.fit(seq, y, epochs = 20, validation_split = .1, shuffle = True, batch_size = 32, callbacks=callback_ear)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "998/998 [==============================] - ETA: 0s - loss: 1.3494 - accuracy: 0.4397\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.62007, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 18s 18ms/step - loss: 1.3494 - accuracy: 0.4397 - val_loss: 1.0135 - val_accuracy: 0.6201\n",
            "Epoch 2/20\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.9508 - accuracy: 0.6345\n",
            "Epoch 00002: val_accuracy improved from 0.62007 to 0.67559, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.9508 - accuracy: 0.6345 - val_loss: 0.8573 - val_accuracy: 0.6756\n",
            "Epoch 3/20\n",
            "996/998 [============================>.] - ETA: 0s - loss: 0.8014 - accuracy: 0.7026\n",
            "Epoch 00003: val_accuracy improved from 0.67559 to 0.72971, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.8011 - accuracy: 0.7027 - val_loss: 0.7562 - val_accuracy: 0.7297\n",
            "Epoch 4/20\n",
            "995/998 [============================>.] - ETA: 0s - loss: 0.6958 - accuracy: 0.7568\n",
            "Epoch 00004: val_accuracy improved from 0.72971 to 0.74634, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.6958 - accuracy: 0.7568 - val_loss: 0.7121 - val_accuracy: 0.7463\n",
            "Epoch 5/20\n",
            "996/998 [============================>.] - ETA: 0s - loss: 0.6163 - accuracy: 0.7929\n",
            "Epoch 00005: val_accuracy improved from 0.74634 to 0.76409, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 18s 18ms/step - loss: 0.6163 - accuracy: 0.7929 - val_loss: 0.6624 - val_accuracy: 0.7641\n",
            "Epoch 6/20\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.8166\n",
            "Epoch 00006: val_accuracy improved from 0.76409 to 0.77508, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.5555 - accuracy: 0.8166 - val_loss: 0.6827 - val_accuracy: 0.7751\n",
            "Epoch 7/20\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.5048 - accuracy: 0.8370\n",
            "Epoch 00007: val_accuracy improved from 0.77508 to 0.79481, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 18s 18ms/step - loss: 0.5047 - accuracy: 0.8371 - val_loss: 0.6086 - val_accuracy: 0.7948\n",
            "Epoch 8/20\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.8465\n",
            "Epoch 00008: val_accuracy improved from 0.79481 to 0.80327, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.4747 - accuracy: 0.8465 - val_loss: 0.5971 - val_accuracy: 0.8033\n",
            "Epoch 9/20\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.8558\n",
            "Epoch 00009: val_accuracy improved from 0.80327 to 0.81088, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.4491 - accuracy: 0.8558 - val_loss: 0.5832 - val_accuracy: 0.8109\n",
            "Epoch 10/20\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8625\n",
            "Epoch 00010: val_accuracy improved from 0.81088 to 0.81567, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.4272 - accuracy: 0.8625 - val_loss: 0.5824 - val_accuracy: 0.8157\n",
            "Epoch 11/20\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.4139 - accuracy: 0.8675\n",
            "Epoch 00011: val_accuracy did not improve from 0.81567\n",
            "998/998 [==============================] - 16s 16ms/step - loss: 0.4139 - accuracy: 0.8675 - val_loss: 0.5818 - val_accuracy: 0.8120\n",
            "Epoch 12/20\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.4010 - accuracy: 0.8735\n",
            "Epoch 00012: val_accuracy improved from 0.81567 to 0.81623, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.4012 - accuracy: 0.8734 - val_loss: 0.5810 - val_accuracy: 0.8162\n",
            "Epoch 13/20\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8793\n",
            "Epoch 00013: val_accuracy did not improve from 0.81623\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.3860 - accuracy: 0.8792 - val_loss: 0.5704 - val_accuracy: 0.8123\n",
            "Epoch 14/20\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8807\n",
            "Epoch 00014: val_accuracy improved from 0.81623 to 0.82018, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.3805 - accuracy: 0.8805 - val_loss: 0.5692 - val_accuracy: 0.8202\n",
            "Epoch 15/20\n",
            "996/998 [============================>.] - ETA: 0s - loss: 0.3616 - accuracy: 0.8876\n",
            "Epoch 00015: val_accuracy did not improve from 0.82018\n",
            "998/998 [==============================] - 17s 17ms/step - loss: 0.3618 - accuracy: 0.8875 - val_loss: 0.5900 - val_accuracy: 0.8123\n",
            "Epoch 16/20\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.8916\n",
            "Epoch 00016: val_accuracy improved from 0.82018 to 0.82159, saving model to 1201_1.h5\n",
            "998/998 [==============================] - 16s 16ms/step - loss: 0.3516 - accuracy: 0.8916 - val_loss: 0.5827 - val_accuracy: 0.8216\n",
            "Epoch 17/20\n",
            "996/998 [============================>.] - ETA: 0s - loss: 0.3480 - accuracy: 0.8928\n",
            "Epoch 00017: val_accuracy did not improve from 0.82159\n",
            "998/998 [==============================] - 16s 16ms/step - loss: 0.3482 - accuracy: 0.8928 - val_loss: 0.6459 - val_accuracy: 0.8002\n",
            "Epoch 18/20\n",
            "996/998 [============================>.] - ETA: 0s - loss: 0.3368 - accuracy: 0.8959\n",
            "Epoch 00018: val_accuracy did not improve from 0.82159\n",
            "998/998 [==============================] - 16s 16ms/step - loss: 0.3365 - accuracy: 0.8959 - val_loss: 0.6173 - val_accuracy: 0.8176\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8a4c6c45f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNdgSODsGy7U"
      },
      "source": [
        "model1 = load_model('1201_1.h5')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXhiXZBEG3e5"
      },
      "source": [
        "pred1 = model1.predict(target)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlhyHP0137Pt"
      },
      "source": [
        "## Model 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwksmImk8Yvr",
        "outputId": "9b8e7b4a-52c5-4f6f-89a3-f77782168b9e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size , 128, input_length = max_len))\n",
        "model.add(SpatialDropout1D(.5))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(5, activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 250, 128)          1637632   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 250, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 250, 128)          98816     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 1,737,093\n",
            "Trainable params: 1,737,093\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adBIQUib-zv6",
        "outputId": "e27c13c0-dd55-458e-98a8-3a96144b9c8c"
      },
      "source": [
        "model.compile(optimizer = RMSprop(lr = .0005), metrics = 'accuracy', loss = 'sparse_categorical_crossentropy')\n",
        "callback_ear = [EarlyStopping(monitor = 'val_accuracy', patience = 2, mode = 'max', verbose = 1), ModelCheckpoint(filepath = '1201_2.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max',verbose = 1)]\n",
        "model.fit(seq, y, epochs = 30, validation_split = .1, shuffle = True, batch_size = 32, callbacks= callback_ear)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "998/998 [==============================] - ETA: 0s - loss: 1.3617 - accuracy: 0.4167\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.58822, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 29s 29ms/step - loss: 1.3617 - accuracy: 0.4167 - val_loss: 1.0253 - val_accuracy: 0.5882\n",
            "Epoch 2/30\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.9545 - accuracy: 0.6215\n",
            "Epoch 00002: val_accuracy improved from 0.58822 to 0.69053, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.9543 - accuracy: 0.6217 - val_loss: 0.8087 - val_accuracy: 0.6905\n",
            "Epoch 3/30\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.7776 - accuracy: 0.7054\n",
            "Epoch 00003: val_accuracy improved from 0.69053 to 0.74831, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.7778 - accuracy: 0.7054 - val_loss: 0.6870 - val_accuracy: 0.7483\n",
            "Epoch 4/30\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.7577\n",
            "Epoch 00004: val_accuracy improved from 0.74831 to 0.76127, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.6658 - accuracy: 0.7577 - val_loss: 0.6723 - val_accuracy: 0.7613\n",
            "Epoch 5/30\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.5867 - accuracy: 0.7934\n",
            "Epoch 00005: val_accuracy improved from 0.76127 to 0.78157, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.5867 - accuracy: 0.7934 - val_loss: 0.6101 - val_accuracy: 0.7816\n",
            "Epoch 6/30\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.5354 - accuracy: 0.8119\n",
            "Epoch 00006: val_accuracy improved from 0.78157 to 0.79200, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 27s 28ms/step - loss: 0.5352 - accuracy: 0.8120 - val_loss: 0.5657 - val_accuracy: 0.7920\n",
            "Epoch 7/30\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.4957 - accuracy: 0.8258\n",
            "Epoch 00007: val_accuracy improved from 0.79200 to 0.80214, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.4959 - accuracy: 0.8257 - val_loss: 0.5535 - val_accuracy: 0.8021\n",
            "Epoch 8/30\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.4671 - accuracy: 0.8378\n",
            "Epoch 00008: val_accuracy improved from 0.80214 to 0.80722, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.4671 - accuracy: 0.8378 - val_loss: 0.5450 - val_accuracy: 0.8072\n",
            "Epoch 9/30\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8453\n",
            "Epoch 00009: val_accuracy improved from 0.80722 to 0.81172, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 27s 28ms/step - loss: 0.4501 - accuracy: 0.8453 - val_loss: 0.5355 - val_accuracy: 0.8117\n",
            "Epoch 10/30\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8527\n",
            "Epoch 00010: val_accuracy improved from 0.81172 to 0.81793, saving model to 1201_2.h5\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.4281 - accuracy: 0.8528 - val_loss: 0.5453 - val_accuracy: 0.8179\n",
            "Epoch 11/30\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.4113 - accuracy: 0.8581\n",
            "Epoch 00011: val_accuracy did not improve from 0.81793\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.4113 - accuracy: 0.8581 - val_loss: 0.5240 - val_accuracy: 0.8176\n",
            "Epoch 12/30\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.3947 - accuracy: 0.8657\n",
            "Epoch 00012: val_accuracy did not improve from 0.81793\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.3947 - accuracy: 0.8657 - val_loss: 0.5423 - val_accuracy: 0.8157\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8a4c545c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC_hQKnNoGkd"
      },
      "source": [
        "model2 = load_model('1201_2.h5')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgJnqW02oJzL"
      },
      "source": [
        "pred2 = model2.predict(target)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1rC-2YvlPmY"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128, input_length= max_len))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Bidirectional(GRU(64, dropout = .4,return_sequences=True)))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(.4))\n",
        "model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF9UAPwsl496",
        "outputId": "76d623eb-d9a9-4c6b-cf0d-bb937f4f759c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 250, 128)          1637632   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 250, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 250, 128)          74496     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 1,712,773\n",
            "Trainable params: 1,712,773\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKJHBTi8l8Ro"
      },
      "source": [
        "model.compile(optimizer = RMSprop(lr = .0005), metrics = 'accuracy', loss = 'sparse_categorical_crossentropy')\n",
        "callback_ear = [EarlyStopping(monitor = 'val_accuracy', patience = 3, mode = 'max', verbose = 1), ModelCheckpoint(filepath = '1201_3.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max',verbose = 1)]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z7t75apmDiO",
        "outputId": "594af662-7423-41d9-e066-a5864fa81458"
      },
      "source": [
        "model.fit(seq, y, epochs = 50, validation_split = .1, shuffle = True, batch_size = 32, callbacks=callback_ear)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 1.3619 - accuracy: 0.4219\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.59301, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 29s 29ms/step - loss: 1.3619 - accuracy: 0.4219 - val_loss: 1.0394 - val_accuracy: 0.5930\n",
            "Epoch 2/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.9483 - accuracy: 0.6284\n",
            "Epoch 00002: val_accuracy improved from 0.59301 to 0.69307, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 27s 28ms/step - loss: 0.9480 - accuracy: 0.6286 - val_loss: 0.8142 - val_accuracy: 0.6931\n",
            "Epoch 3/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.7563 - accuracy: 0.7172\n",
            "Epoch 00003: val_accuracy improved from 0.69307 to 0.74915, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.7563 - accuracy: 0.7172 - val_loss: 0.6767 - val_accuracy: 0.7492\n",
            "Epoch 4/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.6322 - accuracy: 0.7716\n",
            "Epoch 00004: val_accuracy improved from 0.74915 to 0.78382, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.6327 - accuracy: 0.7714 - val_loss: 0.6011 - val_accuracy: 0.7838\n",
            "Epoch 5/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.8048\n",
            "Epoch 00005: val_accuracy improved from 0.78382 to 0.79735, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.5512 - accuracy: 0.8048 - val_loss: 0.5683 - val_accuracy: 0.7974\n",
            "Epoch 6/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.8243\n",
            "Epoch 00006: val_accuracy improved from 0.79735 to 0.80665, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.4944 - accuracy: 0.8243 - val_loss: 0.5375 - val_accuracy: 0.8067\n",
            "Epoch 7/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.8387\n",
            "Epoch 00007: val_accuracy did not improve from 0.80665\n",
            "998/998 [==============================] - 26s 26ms/step - loss: 0.4574 - accuracy: 0.8387 - val_loss: 0.5649 - val_accuracy: 0.8061\n",
            "Epoch 8/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.4274 - accuracy: 0.8520\n",
            "Epoch 00008: val_accuracy improved from 0.80665 to 0.81454, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.4272 - accuracy: 0.8521 - val_loss: 0.5280 - val_accuracy: 0.8145\n",
            "Epoch 9/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8601\n",
            "Epoch 00009: val_accuracy improved from 0.81454 to 0.82300, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 26s 27ms/step - loss: 0.3980 - accuracy: 0.8601 - val_loss: 0.5111 - val_accuracy: 0.8230\n",
            "Epoch 10/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8671\n",
            "Epoch 00010: val_accuracy did not improve from 0.82300\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.3796 - accuracy: 0.8670 - val_loss: 0.5188 - val_accuracy: 0.8202\n",
            "Epoch 11/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8708\n",
            "Epoch 00011: val_accuracy improved from 0.82300 to 0.82384, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.3655 - accuracy: 0.8708 - val_loss: 0.5133 - val_accuracy: 0.8238\n",
            "Epoch 12/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.8767\n",
            "Epoch 00012: val_accuracy improved from 0.82384 to 0.82497, saving model to 1201_3.h5\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.3505 - accuracy: 0.8768 - val_loss: 0.5084 - val_accuracy: 0.8250\n",
            "Epoch 13/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8824\n",
            "Epoch 00013: val_accuracy did not improve from 0.82497\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.3366 - accuracy: 0.8824 - val_loss: 0.5366 - val_accuracy: 0.8196\n",
            "Epoch 14/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8844\n",
            "Epoch 00014: val_accuracy did not improve from 0.82497\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.3298 - accuracy: 0.8844 - val_loss: 0.5282 - val_accuracy: 0.8179\n",
            "Epoch 15/50\n",
            "996/998 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.8889\n",
            "Epoch 00015: val_accuracy did not improve from 0.82497\n",
            "998/998 [==============================] - 27s 27ms/step - loss: 0.3152 - accuracy: 0.8889 - val_loss: 0.5394 - val_accuracy: 0.8196\n",
            "Epoch 00015: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8a1812ff98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmVlc0rqvMqL"
      },
      "source": [
        "model3 = load_model('1201_3.h5')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Xoqq_1vOvG"
      },
      "source": [
        "pred3 = model3.predict(target)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzPOtllClNno"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128, input_length= max_len))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Conv1D(64, 5, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Bidirectional(GRU(64, dropout = .4,return_sequences=True)))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(.4))\n",
        "model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRJ7nqGmmaDr",
        "outputId": "3601cbed-2ac8-4eda-80cc-b3debb453703"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 250, 128)          1637632   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 250, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 250, 64)           41024     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 250, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 250, 128)          49920     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 1,729,221\n",
            "Trainable params: 1,729,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO6jIS8QmhBt"
      },
      "source": [
        "model.compile(optimizer = RMSprop(lr = .0005), metrics = 'accuracy', loss = 'sparse_categorical_crossentropy')\n",
        "callback_ear = [EarlyStopping(monitor = 'val_accuracy', patience = 3, mode = 'max', verbose = 1), ModelCheckpoint(filepath = '1201_4.h5', monitor = 'val_accuracy', save_best_only = True, mode = 'max',verbose = 1)]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3Aj6GJPmehL",
        "outputId": "806e0b63-658e-453d-f0d3-a9b34fe1baf5"
      },
      "source": [
        "model.fit(seq, y, epochs = 50, validation_split = .1, shuffle = True, batch_size = 32,callbacks=callback_ear)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 1.3588 - accuracy: 0.4025\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.58681, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 30s 30ms/step - loss: 1.3587 - accuracy: 0.4025 - val_loss: 1.0426 - val_accuracy: 0.5868\n",
            "Epoch 2/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.9265 - accuracy: 0.6263\n",
            "Epoch 00002: val_accuracy improved from 0.58681 to 0.68997, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 30s 30ms/step - loss: 0.9265 - accuracy: 0.6263 - val_loss: 0.8062 - val_accuracy: 0.6900\n",
            "Epoch 3/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.7426 - accuracy: 0.7167\n",
            "Epoch 00003: val_accuracy improved from 0.68997 to 0.73534, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 30s 30ms/step - loss: 0.7426 - accuracy: 0.7167 - val_loss: 0.7057 - val_accuracy: 0.7353\n",
            "Epoch 4/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.7693\n",
            "Epoch 00004: val_accuracy improved from 0.73534 to 0.74944, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 30s 30ms/step - loss: 0.6282 - accuracy: 0.7693 - val_loss: 0.6647 - val_accuracy: 0.7494\n",
            "Epoch 5/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.5568 - accuracy: 0.8004\n",
            "Epoch 00005: val_accuracy improved from 0.74944 to 0.77649, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 30s 30ms/step - loss: 0.5566 - accuracy: 0.8005 - val_loss: 0.6075 - val_accuracy: 0.7765\n",
            "Epoch 6/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.8200\n",
            "Epoch 00006: val_accuracy improved from 0.77649 to 0.79369, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 30s 30ms/step - loss: 0.4971 - accuracy: 0.8200 - val_loss: 0.5731 - val_accuracy: 0.7937\n",
            "Epoch 7/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.4551 - accuracy: 0.8389\n",
            "Epoch 00007: val_accuracy improved from 0.79369 to 0.80017, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 30s 30ms/step - loss: 0.4551 - accuracy: 0.8389 - val_loss: 0.5603 - val_accuracy: 0.8002\n",
            "Epoch 8/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.4211 - accuracy: 0.8529\n",
            "Epoch 00008: val_accuracy improved from 0.80017 to 0.80778, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 29s 29ms/step - loss: 0.4212 - accuracy: 0.8528 - val_loss: 0.5497 - val_accuracy: 0.8078\n",
            "Epoch 9/50\n",
            "998/998 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8629\n",
            "Epoch 00009: val_accuracy improved from 0.80778 to 0.81680, saving model to 1201_4.h5\n",
            "998/998 [==============================] - 29s 29ms/step - loss: 0.3952 - accuracy: 0.8629 - val_loss: 0.5269 - val_accuracy: 0.8168\n",
            "Epoch 10/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.3730 - accuracy: 0.8670\n",
            "Epoch 00010: val_accuracy did not improve from 0.81680\n",
            "998/998 [==============================] - 28s 29ms/step - loss: 0.3732 - accuracy: 0.8670 - val_loss: 0.5366 - val_accuracy: 0.8089\n",
            "Epoch 11/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.3545 - accuracy: 0.8755\n",
            "Epoch 00011: val_accuracy did not improve from 0.81680\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.3544 - accuracy: 0.8756 - val_loss: 0.5578 - val_accuracy: 0.8109\n",
            "Epoch 12/50\n",
            "997/998 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.8809\n",
            "Epoch 00012: val_accuracy did not improve from 0.81680\n",
            "998/998 [==============================] - 28s 28ms/step - loss: 0.3390 - accuracy: 0.8810 - val_loss: 0.5372 - val_accuracy: 0.8143\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8a13b2f748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDNFkgAG2UXL"
      },
      "source": [
        "model4 = load_model('1201_4.h5')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWwaXvzpxmr6"
      },
      "source": [
        "pred4 = model4.predict(target)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2wNXeAZxoYw"
      },
      "source": [
        "pred = (pred1 * pred2 * pred3 * pred4) ** .25"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbKQKXQBxrgo"
      },
      "source": [
        "submission[['0','1','2','3','4']] = pred"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOKX-rht61c4"
      },
      "source": [
        "submission.to_csv('1201_2.csv', index = False)"
      ],
      "execution_count": 72,
      "outputs": []
    }
  ]
}