# 월간 DACON 소설 작가 분류 AI 경진대회

### 대회 기간 : 2020.10.29 ~ 2020.12.04
### 랭크 
        public : 63/284(log loss = 0.35098)
        private : 65/284(log loss = 0.36046)
        제출횟수 : 41회

## < 리뷰 ><br>

* '비정형 데이터는 딥러닝이다!'에서 벗어나지 못하고 계속 딥러닝 기법만 사용
    - 최상위권의 유저들의 코드를 보면 거의 모두(?) 머신러닝 기법을 활용함.
    - 간단한 pytorch 코드를 활용한 상위권 코드도 존재함. -> pytorch의 효율성 실감<br>
    
* 딥러닝 기법 고집으로 인해서 다양한 모델 후보군 축소 및 텍스트 전처리의 다양성 확보 어려움
    - LSTM, GRU, Conv1D는 물론 concatnate 등 여러 모델을 짬뽕(?) 및 다양한 계층 구조를 사용해 보았지만 이번 대회에서는 garbage in garbage out을 깨달음
    - 영문의 특성상 전치사 및 관사가 최빈도 단어들로 나타났고 광범위한 텍스트 전처리에 어려움을 겪음.<br>    
* kaggle의 중요성을 깨달음
    - 최상위권 코드들을 살펴보면 ML을 사용한 경우 모두 kaggle의 특정 notebook을 참고했다고 명시되어 있음.
    - kaggle의 여러 커널들을 참고하면서 공부하는게 장기적으로도 매우 필요하다고 생각이 다시 한 번 듦.<br>
    
* 5 class 예측 문제이기 때문에 5개의 class를 잘 구분할 수 있는 feature를 생성할 수 있는 ML(XGB, MultinomialNB 등) 사용이 좋았을 것 같음.<br><br>

## < 의의 >

* validation 구축을 위해 여러 시도를 해보았음.
    - test 데이터의 분포를 맞추기 위해서 토큰 수를 기준으로 train 데이터에서 validation 셋을 구축하는 시도를 해봄.<br>

    
