{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CONV1D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnzMigFa-NRr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/dacon/review/"
      ],
      "metadata": {
        "id": "_GoF2ILZNDSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "u0ekK8IXNTpH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
      ],
      "metadata": {
        "id": "Z6iZK4NotGcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab, Kkma"
      ],
      "metadata": {
        "id": "7bxRmTgBtGj-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc = Mecab()\n",
        "kk = Kkma()"
      ],
      "metadata": {
        "id": "wHWfvexitJae"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "UQL38iFJNPmI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['document'] = train['document'].str.replace('ㅡㅡ', '화남')\n",
        "test['document'] = test['document'].str.replace('ㅡㅡ', '화남')"
      ],
      "metadata": {
        "id": "8BToKnsTsoeo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['doc_length'] = train.document.apply(len)"
      ],
      "metadata": {
        "id": "c2trBBTJNS6l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.doc_length.min()"
      ],
      "metadata": {
        "id": "u-5A8SXnNOma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b597169-45ea-4b86-811b-0da930314c74"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc.pos(train.document[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcVYfkNCtxMo",
        "outputId": "3aa6b1ec-5543-4787-8613-67940e3139f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('영상', 'NNG'),\n",
              " ('이나', 'JC'),\n",
              " ('음악', 'NNG'),\n",
              " ('이', 'JKS'),\n",
              " ('이쁘', 'VA'),\n",
              " ('다', 'EC'),\n",
              " ('해도', 'VV+EC'),\n",
              " ('미', 'NNG'),\n",
              " ('화', 'XSN'),\n",
              " ('시킨', 'XSV+ETM'),\n",
              " ('불륜', 'NNG'),\n",
              " ('일', 'VCP+ETM'),\n",
              " ('뿐', 'NNB')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc.pos(test.document[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHoWXj79uLPl",
        "outputId": "cabb7ffd-d585-4972-b7f4-a7f033c591d6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('시간', 'NNG'),\n",
              " ('때우', 'VV'),\n",
              " ('기', 'ETN'),\n",
              " ('좋', 'VA'),\n",
              " ('은', 'ETM'),\n",
              " ('영화', 'NNG'),\n",
              " ('지루함', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc.pos(test.document[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMh2XplZuQzE",
        "outputId": "5b8a8814-b428-4986-a24b-52d6edf81410"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('나가토', 'NNP'),\n",
              " ('의', 'JKG'),\n",
              " ('나가토', 'NNP'),\n",
              " ('에', 'JKB'),\n",
              " ('의한', 'VV+ETM'),\n",
              " ('나가토', 'NNP'),\n",
              " ('를', 'JKO'),\n",
              " ('위한', 'VV+ETM')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc.pos(test.document[500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yobtPFbvrxI",
        "outputId": "4f1a41d8-f59c-421b-9f90-588418526cbf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('하', 'IC'),\n",
              " ('.', 'SF'),\n",
              " ('..', 'SY'),\n",
              " ('이렇게', 'MAG'),\n",
              " ('재밌', 'VA'),\n",
              " ('는', 'ETM'),\n",
              " ('영화', 'NNG'),\n",
              " ('를', 'JKO'),\n",
              " ('이', 'MM'),\n",
              " ('따구', 'NNG'),\n",
              " ('로', 'JKB'),\n",
              " ('밖에', 'JX'),\n",
              " ('못살', 'VV+ETM'),\n",
              " ('이', 'VCP'),\n",
              " ('다니', 'EF'),\n",
              " ('.', 'SF'),\n",
              " ('.', 'SY'),\n",
              " ('참', 'IC'),\n",
              " ('감독', 'NNG'),\n",
              " ('이', 'JKS'),\n",
              " ('호구', 'NNG'),\n",
              " ('네', 'XSA+EC')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc.pos(test.document[2500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foLgiFISv6Mt",
        "outputId": "54a338bd-4836-4553-dfbd-ecbc7b03db34"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('잊', 'VV'),\n",
              " ('을', 'ETM'),\n",
              " ('수', 'NNB'),\n",
              " ('없', 'VA'),\n",
              " ('는', 'ETM'),\n",
              " ('조커', 'NNG'),\n",
              " ('와', 'JC'),\n",
              " ('배트맨', 'NNP'),\n",
              " ('.', 'SF'),\n",
              " ('.', 'SY'),\n",
              " ('킴', 'NNP'),\n",
              " ('누나', 'NNG'),\n",
              " ('의', 'JKG'),\n",
              " ('미모', 'NNG'),\n",
              " ('도', 'JX'),\n",
              " ('.', 'SF'),\n",
              " ('..', 'SY')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_corpus_cnt(data) :\n",
        "  pos_corpus = []\n",
        "  cnt = []\n",
        "  for doc in data.document :\n",
        "    doc_pos = mc.pos(doc)\n",
        "    pos_list = []\n",
        "    for value in doc_pos :\n",
        "      if value[1].startswith('N') or value[1].startswith('VA') or value[1].startswith('VV') or value[1].startswith('MA') :\n",
        "        pos_list.append(value[0])\n",
        "        cnt.append(value[0])\n",
        "      else :\n",
        "        pass\n",
        "    pos_corpus.append(pos_list)\n",
        "  \n",
        "  return pos_corpus, cnt"
      ],
      "metadata": {
        "id": "BGSq_fQ9s1pI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_pos, tr_cnt = get_pos_corpus_cnt(train)\n",
        "te_pos, te_cnt = get_pos_corpus_cnt(test)"
      ],
      "metadata": {
        "id": "kf0xaPMkyXaC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "f0-gTTSHwbYc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_cnt = Counter(cnt)"
      ],
      "metadata": {
        "id": "AXASUaLrwo6u"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['pos_corpus'] = tr_pos\n",
        "test['pos_corpus'] = te_pos"
      ],
      "metadata": {
        "id": "XaVjlVrNs5j_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,  ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import *\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop"
      ],
      "metadata": {
        "id": "463O5ihmyg92"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train['pos_corpus']\n",
        "X_test = test['pos_corpus']\n",
        "\n",
        "y_train = np.array(train.label)"
      ],
      "metadata": {
        "id": "gX7jzjrWy51b"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "ldW1x4xpypAU"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 3\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oujc3L8byOWG",
        "outputId": "867d74ea-d5f9-4361-f092-776d11b8db4e"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 6236\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 4576\n",
            "단어 집합에서 희귀 단어의 비율: 73.38037203335472\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 16.156613007842445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = total_cnt - rare_cnt + 1 # 전체 단어 개수 중 빈도수 5이하인 단어 개수는 제거. 0번 패딩 토큰을 고려하여 +1\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvvdRpjvyv6l",
        "outputId": "117777cb-8135-4e04-8620-a36a2e32a4e3"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 1661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "token_X_train = tokenizer.texts_to_sequences(X_train)\n",
        "token_X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "FuYD7Pefy12m"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_train = [index for index, sentence in enumerate(token_X_train) if len(sentence) < 1]"
      ],
      "metadata": {
        "id": "lpQ68qEfy-gU"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈 샘플들을 제거\n",
        "del_X_train = np.delete(token_X_train, drop_train, axis=0)\n",
        "del_y_train = np.delete(y_train, drop_train, axis=0)\n",
        "print(len(del_X_train))\n",
        "print(len(del_y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC2dj71LzDCv",
        "outputId": "359e1339-8dee-4e75-d0f8-b61d5898d418"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4983\n",
            "4983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "yyYREpbkzUuF"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('train data의 최대 길이 :',max(len(l) for l in del_X_train))\n",
        "print('train data의 평균 길이 :',sum(map(len, del_X_train))/len(del_X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "uqs8y_u1zH7C",
        "outputId": "5c6b991b-1346-4723-955d-2d0d7c81ec2c"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data의 최대 길이 : 25\n",
            "train data의 평균 길이 : 5.707003812964078\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test data의 최대 길이 : \", max(len(l) for l in token_X_test))\n",
        "print(\"test data의 평균 길이 : \", sum(map(len, token_X_test))/ len(token_X_test))\n",
        "plt.hist([len(s) for s in token_X_test], bins=50)\n",
        "plt.xlabel('length of Data')\n",
        "plt.ylabel('number of Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "bAvtg-7JzRvr",
        "outputId": "079f4611-3d12-4c2a-dc0f-ed10bc1de896"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test data의 최대 길이 :  15\n",
            "test data의 평균 길이 :  5.4646\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "    cnt = 0\n",
        "    for s in nested_list:\n",
        "        if(len(s) <= max_len):\n",
        "            cnt = cnt + 1\n",
        "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
      ],
      "metadata": {
        "id": "pgqg9q5yzYt_"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 25\n",
        "below_threshold_len(max_len, del_X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e_LOYDZzbQz",
        "outputId": "6b3d2fa4-a5d0-4934-bf19-537691db4f0a"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 25 이하인 샘플의 비율: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(del_X_train, maxlen = max_len)\n",
        "target = pad_sequences(token_X_test, maxlen = max_len)"
      ],
      "metadata": {
        "id": "p6wscpF4zch2"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = del_y_train.copy()"
      ],
      "metadata": {
        "id": "kGtVXKQJ17y3"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "VWQUndlq1qxO"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits = 10, random_state = 42, shuffle = True)"
      ],
      "metadata": {
        "id": "1tw6e-0R1vpO"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1_pred = np.zeros(target.shape[0])\n",
        "for n, (tr_idx, val_idx) in enumerate(skf.split(X, y)) :\n",
        "  tr_x, tr_y = X[tr_idx], y[tr_idx]\n",
        "  val_x, val_y = X[val_idx], y[val_idx]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 128, input_length = max_len))\n",
        "  model.add(Conv1D(64, 5, activation = 'relu', padding = 'same', kernel_regularizer = l2(0.01)))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "  model.compile(optimizer = Adam(lr = .0003), loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "  reLR = ReduceLROnPlateau(patience = 5, verbose = 1, factor = .9)\n",
        "  es = EarlyStopping(monitor = 'val_acc', mode = 'max', verbose = 1, patience = 15)\n",
        "  mc = ModelCheckpoint(filepath = '1st_model.h5', monitor = 'val_acc', mode = 'max', verbose = 1, save_best_only = True, restore_best_weights = True)\n",
        "\n",
        "  history = model.fit(tr_x, tr_y, epochs = 300, batch_size= 32, shuffle = True, validation_split = 0.2, verbose = 1, callbacks = [es, mc, reLR])\n",
        "  best = load_model('1st_model.h5')\n",
        "  val_pred = [v[0] for v in best.predict(val_x)]\n",
        "  val_cls = [1 if v >= 0.5 else 0 for v in val_pred]\n",
        "  val_acc = accuracy_score(val_y, val_cls)\n",
        "  print(f'{n + 1}Fold ACC = {val_acc}\\n')\n",
        "\n",
        "  fold_pred = [v[0] / 10 for v in best.predict(target)]\n",
        "  model1_pred += fold_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBMG61G41zfK",
        "outputId": "68c045e8-46b6-467a-d9fd-1871ccb98ea7"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 1.1786 - acc: 0.5999\n",
            "Epoch 00001: val_acc improved from -inf to 0.56856, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1786 - acc: 0.5999 - val_loss: 0.9174 - val_acc: 0.5686 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.7983 - acc: 0.7585\n",
            "Epoch 00002: val_acc improved from 0.56856 to 0.78818, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7942 - acc: 0.7614 - val_loss: 0.7098 - val_acc: 0.7882 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.6235 - acc: 0.8600\n",
            "Epoch 00003: val_acc improved from 0.78818 to 0.81048, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6208 - acc: 0.8564 - val_loss: 0.5702 - val_acc: 0.8105 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.4787 - acc: 0.8807\n",
            "Epoch 00004: val_acc improved from 0.81048 to 0.82274, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4773 - acc: 0.8798 - val_loss: 0.4993 - val_acc: 0.8227 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.3981 - acc: 0.9006\n",
            "Epoch 00005: val_acc improved from 0.82274 to 0.82943, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3972 - acc: 0.9013 - val_loss: 0.4689 - val_acc: 0.8294 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.3499 - acc: 0.9155\n",
            "Epoch 00006: val_acc improved from 0.82943 to 0.83055, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3495 - acc: 0.9152 - val_loss: 0.4557 - val_acc: 0.8305 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.3134 - acc: 0.9297\n",
            "Epoch 00007: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3147 - acc: 0.9295 - val_loss: 0.4472 - val_acc: 0.8283 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.9375\n",
            "Epoch 00008: val_acc improved from 0.83055 to 0.83278, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2877 - acc: 0.9367 - val_loss: 0.4507 - val_acc: 0.8328 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.2655 - acc: 0.9445\n",
            "Epoch 00009: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2668 - acc: 0.9437 - val_loss: 0.4450 - val_acc: 0.8261 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.2486 - acc: 0.9459\n",
            "Epoch 00010: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2485 - acc: 0.9459 - val_loss: 0.4446 - val_acc: 0.8305 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.2316 - acc: 0.9527\n",
            "Epoch 00011: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2324 - acc: 0.9520 - val_loss: 0.4525 - val_acc: 0.8216 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.2187 - acc: 0.9572\n",
            "Epoch 00012: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2192 - acc: 0.9571 - val_loss: 0.4496 - val_acc: 0.8205 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "101/113 [=========================>....] - ETA: 0s - loss: 0.2035 - acc: 0.9623\n",
            "Epoch 00013: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2072 - acc: 0.9604 - val_loss: 0.4546 - val_acc: 0.8205 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1969 - acc: 0.9633\n",
            "Epoch 00014: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1967 - acc: 0.9635 - val_loss: 0.4580 - val_acc: 0.8205 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1873 - acc: 0.9664\n",
            "Epoch 00015: val_acc did not improve from 0.83278\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1871 - acc: 0.9660 - val_loss: 0.4668 - val_acc: 0.8127 - lr: 3.0000e-04\n",
            "Epoch 16/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9690\n",
            "Epoch 00016: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1776 - acc: 0.9679 - val_loss: 0.4720 - val_acc: 0.8138 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1711 - acc: 0.9688\n",
            "Epoch 00017: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1710 - acc: 0.9693 - val_loss: 0.4761 - val_acc: 0.8116 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1634 - acc: 0.9711\n",
            "Epoch 00018: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.1627 - acc: 0.9713 - val_loss: 0.4806 - val_acc: 0.8127 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1589 - acc: 0.9749\n",
            "Epoch 00019: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.1584 - acc: 0.9755 - val_loss: 0.4850 - val_acc: 0.8082 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1497 - acc: 0.9765\n",
            "Epoch 00020: val_acc did not improve from 0.83278\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1513 - acc: 0.9752 - val_loss: 0.4914 - val_acc: 0.8071 - lr: 2.7000e-04\n",
            "Epoch 21/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1465 - acc: 0.9769\n",
            "Epoch 00021: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1455 - acc: 0.9771 - val_loss: 0.4981 - val_acc: 0.8094 - lr: 2.4300e-04\n",
            "Epoch 22/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1406 - acc: 0.9794\n",
            "Epoch 00022: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1407 - acc: 0.9799 - val_loss: 0.5148 - val_acc: 0.8149 - lr: 2.4300e-04\n",
            "Epoch 23/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1376 - acc: 0.9798\n",
            "Epoch 00023: val_acc did not improve from 0.83278\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1366 - acc: 0.9805 - val_loss: 0.5059 - val_acc: 0.8071 - lr: 2.4300e-04\n",
            "Epoch 00023: early stopping\n",
            "1Fold ACC = 0.845691382765531\n",
            "\n",
            "Epoch 1/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 1.1799 - acc: 0.6165\n",
            "Epoch 00001: val_acc improved from -inf to 0.69342, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 2s 14ms/step - loss: 1.1751 - acc: 0.6167 - val_loss: 0.9126 - val_acc: 0.6934 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.7880 - acc: 0.7834\n",
            "Epoch 00002: val_acc improved from 0.69342 to 0.79264, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7880 - acc: 0.7834 - val_loss: 0.6977 - val_acc: 0.7926 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.6088 - acc: 0.8562\n",
            "Epoch 00003: val_acc improved from 0.79264 to 0.81494, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6071 - acc: 0.8548 - val_loss: 0.5601 - val_acc: 0.8149 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.4702 - acc: 0.8788\n",
            "Epoch 00004: val_acc improved from 0.81494 to 0.82609, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4689 - acc: 0.8790 - val_loss: 0.4952 - val_acc: 0.8261 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.3948 - acc: 0.8987\n",
            "Epoch 00005: val_acc improved from 0.82609 to 0.82832, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3932 - acc: 0.8988 - val_loss: 0.4655 - val_acc: 0.8283 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.3487 - acc: 0.9171\n",
            "Epoch 00006: val_acc improved from 0.82832 to 0.83389, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3464 - acc: 0.9172 - val_loss: 0.4515 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.3131 - acc: 0.9291\n",
            "Epoch 00007: val_acc did not improve from 0.83389\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3124 - acc: 0.9289 - val_loss: 0.4414 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.2849 - acc: 0.9396\n",
            "Epoch 00008: val_acc improved from 0.83389 to 0.83946, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2855 - acc: 0.9389 - val_loss: 0.4377 - val_acc: 0.8395 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.2678 - acc: 0.9423\n",
            "Epoch 00009: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2656 - acc: 0.9431 - val_loss: 0.4371 - val_acc: 0.8372 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.2446 - acc: 0.9502\n",
            "Epoch 00010: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2479 - acc: 0.9495 - val_loss: 0.4374 - val_acc: 0.8317 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9521\n",
            "Epoch 00011: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2332 - acc: 0.9515 - val_loss: 0.4385 - val_acc: 0.8372 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.2195 - acc: 0.9573\n",
            "Epoch 00012: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2195 - acc: 0.9576 - val_loss: 0.4411 - val_acc: 0.8361 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2082 - acc: 0.9590\n",
            "Epoch 00013: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2082 - acc: 0.9590 - val_loss: 0.4445 - val_acc: 0.8317 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1971 - acc: 0.9623\n",
            "Epoch 00014: val_acc did not improve from 0.83946\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1978 - acc: 0.9618 - val_loss: 0.4493 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1852 - acc: 0.9663\n",
            "Epoch 00015: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1869 - acc: 0.9652 - val_loss: 0.4607 - val_acc: 0.8272 - lr: 2.7000e-04\n",
            "Epoch 16/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1793 - acc: 0.9655\n",
            "Epoch 00016: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1804 - acc: 0.9646 - val_loss: 0.4588 - val_acc: 0.8339 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1725 - acc: 0.9688\n",
            "Epoch 00017: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1730 - acc: 0.9682 - val_loss: 0.4602 - val_acc: 0.8339 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1658 - acc: 0.9715\n",
            "Epoch 00018: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1658 - acc: 0.9716 - val_loss: 0.4642 - val_acc: 0.8317 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1597 - acc: 0.9727\n",
            "Epoch 00019: val_acc did not improve from 0.83946\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1601 - acc: 0.9732 - val_loss: 0.4735 - val_acc: 0.8272 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "101/113 [=========================>....] - ETA: 0s - loss: 0.1525 - acc: 0.9756\n",
            "Epoch 00020: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1533 - acc: 0.9752 - val_loss: 0.4776 - val_acc: 0.8261 - lr: 2.4300e-04\n",
            "Epoch 21/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9754\n",
            "Epoch 00021: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1489 - acc: 0.9755 - val_loss: 0.4836 - val_acc: 0.8283 - lr: 2.4300e-04\n",
            "Epoch 22/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.1455 - acc: 0.9773\n",
            "Epoch 00022: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1442 - acc: 0.9774 - val_loss: 0.4825 - val_acc: 0.8272 - lr: 2.4300e-04\n",
            "Epoch 23/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.1395 - acc: 0.9789\n",
            "Epoch 00023: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1396 - acc: 0.9780 - val_loss: 0.4936 - val_acc: 0.8227 - lr: 2.4300e-04\n",
            "Epoch 00023: early stopping\n",
            "2Fold ACC = 0.8476953907815631\n",
            "\n",
            "Epoch 1/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 1.1946 - acc: 0.5890\n",
            "Epoch 00001: val_acc improved from -inf to 0.75139, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1777 - acc: 0.6011 - val_loss: 0.9139 - val_acc: 0.7514 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.7973 - acc: 0.8248\n",
            "Epoch 00002: val_acc improved from 0.75139 to 0.77592, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7888 - acc: 0.8297 - val_loss: 0.7016 - val_acc: 0.7759 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.6088 - acc: 0.8552\n",
            "Epoch 00003: val_acc improved from 0.77592 to 0.79710, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6088 - acc: 0.8550 - val_loss: 0.5659 - val_acc: 0.7971 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.4687 - acc: 0.8859\n",
            "Epoch 00004: val_acc improved from 0.79710 to 0.81271, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4668 - acc: 0.8843 - val_loss: 0.5006 - val_acc: 0.8127 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.3854 - acc: 0.9066\n",
            "Epoch 00005: val_acc did not improve from 0.81271\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3867 - acc: 0.9069 - val_loss: 0.4745 - val_acc: 0.8105 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.3398 - acc: 0.9179\n",
            "Epoch 00006: val_acc improved from 0.81271 to 0.81940, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3391 - acc: 0.9180 - val_loss: 0.4596 - val_acc: 0.8194 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "101/113 [=========================>....] - ETA: 0s - loss: 0.3064 - acc: 0.9335\n",
            "Epoch 00007: val_acc improved from 0.81940 to 0.82051, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3059 - acc: 0.9314 - val_loss: 0.4541 - val_acc: 0.8205 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.2786 - acc: 0.9375\n",
            "Epoch 00008: val_acc improved from 0.82051 to 0.82609, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2790 - acc: 0.9373 - val_loss: 0.4516 - val_acc: 0.8261 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.2616 - acc: 0.9429\n",
            "Epoch 00009: val_acc did not improve from 0.82609\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2584 - acc: 0.9445 - val_loss: 0.4480 - val_acc: 0.8250 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.2408 - acc: 0.9499\n",
            "Epoch 00010: val_acc improved from 0.82609 to 0.82832, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2403 - acc: 0.9504 - val_loss: 0.4488 - val_acc: 0.8283 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.2242 - acc: 0.9543\n",
            "Epoch 00011: val_acc improved from 0.82832 to 0.83055, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2250 - acc: 0.9534 - val_loss: 0.4503 - val_acc: 0.8305 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.2114 - acc: 0.9583\n",
            "Epoch 00012: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2112 - acc: 0.9585 - val_loss: 0.4588 - val_acc: 0.8227 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1982 - acc: 0.9634\n",
            "Epoch 00013: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1988 - acc: 0.9624 - val_loss: 0.4582 - val_acc: 0.8272 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1852 - acc: 0.9675\n",
            "Epoch 00014: val_acc did not improve from 0.83055\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1882 - acc: 0.9663 - val_loss: 0.4607 - val_acc: 0.8227 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1781 - acc: 0.9670\n",
            "Epoch 00015: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1786 - acc: 0.9668 - val_loss: 0.4725 - val_acc: 0.8250 - lr: 2.7000e-04\n",
            "Epoch 16/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9682\n",
            "Epoch 00016: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1708 - acc: 0.9682 - val_loss: 0.4749 - val_acc: 0.8239 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1628 - acc: 0.9718\n",
            "Epoch 00017: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1632 - acc: 0.9704 - val_loss: 0.4717 - val_acc: 0.8250 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1531 - acc: 0.9763\n",
            "Epoch 00018: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1568 - acc: 0.9741 - val_loss: 0.4807 - val_acc: 0.8227 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1505 - acc: 0.9751\n",
            "Epoch 00019: val_acc did not improve from 0.83055\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1503 - acc: 0.9752 - val_loss: 0.4884 - val_acc: 0.8250 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1442 - acc: 0.9773\n",
            "Epoch 00020: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1447 - acc: 0.9771 - val_loss: 0.4930 - val_acc: 0.8239 - lr: 2.4300e-04\n",
            "Epoch 21/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1397 - acc: 0.9778\n",
            "Epoch 00021: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1395 - acc: 0.9777 - val_loss: 0.4946 - val_acc: 0.8216 - lr: 2.4300e-04\n",
            "Epoch 22/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1356 - acc: 0.9792\n",
            "Epoch 00022: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1352 - acc: 0.9794 - val_loss: 0.4949 - val_acc: 0.8183 - lr: 2.4300e-04\n",
            "Epoch 23/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1307 - acc: 0.9788\n",
            "Epoch 00023: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1307 - acc: 0.9794 - val_loss: 0.4992 - val_acc: 0.8183 - lr: 2.4300e-04\n",
            "Epoch 24/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1253 - acc: 0.9825\n",
            "Epoch 00024: val_acc did not improve from 0.83055\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00021870001510251313.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1265 - acc: 0.9819 - val_loss: 0.5117 - val_acc: 0.8205 - lr: 2.4300e-04\n",
            "Epoch 25/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.1221 - acc: 0.9828\n",
            "Epoch 00025: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1228 - acc: 0.9819 - val_loss: 0.5087 - val_acc: 0.8205 - lr: 2.1870e-04\n",
            "Epoch 26/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1176 - acc: 0.9841\n",
            "Epoch 00026: val_acc did not improve from 0.83055\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1192 - acc: 0.9827 - val_loss: 0.5152 - val_acc: 0.8172 - lr: 2.1870e-04\n",
            "Epoch 00026: early stopping\n",
            "3Fold ACC = 0.843687374749499\n",
            "\n",
            "Epoch 1/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 1.1795 - acc: 0.5508\n",
            "Epoch 00001: val_acc improved from -inf to 0.70457, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 1.1792 - acc: 0.5510 - val_loss: 0.9146 - val_acc: 0.7046 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.7928 - acc: 0.8038\n",
            "Epoch 00002: val_acc improved from 0.70457 to 0.78930, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7928 - acc: 0.8038 - val_loss: 0.7093 - val_acc: 0.7893 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.6248 - acc: 0.8536\n",
            "Epoch 00003: val_acc improved from 0.78930 to 0.81605, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6203 - acc: 0.8534 - val_loss: 0.5728 - val_acc: 0.8161 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.4778 - acc: 0.8793\n",
            "Epoch 00004: val_acc improved from 0.81605 to 0.82832, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4725 - acc: 0.8804 - val_loss: 0.5014 - val_acc: 0.8283 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.3943 - acc: 0.8998\n",
            "Epoch 00005: val_acc improved from 0.82832 to 0.83835, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3907 - acc: 0.9027 - val_loss: 0.4714 - val_acc: 0.8384 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "101/113 [=========================>....] - ETA: 0s - loss: 0.3414 - acc: 0.9239\n",
            "Epoch 00006: val_acc improved from 0.83835 to 0.84281, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3414 - acc: 0.9214 - val_loss: 0.4572 - val_acc: 0.8428 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.3064 - acc: 0.9319\n",
            "Epoch 00007: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3071 - acc: 0.9312 - val_loss: 0.4482 - val_acc: 0.8417 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.2801 - acc: 0.9399\n",
            "Epoch 00008: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2795 - acc: 0.9404 - val_loss: 0.4439 - val_acc: 0.8395 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2567 - acc: 0.9445\n",
            "Epoch 00009: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2567 - acc: 0.9445 - val_loss: 0.4485 - val_acc: 0.8372 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.2378 - acc: 0.9498\n",
            "Epoch 00010: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2379 - acc: 0.9493 - val_loss: 0.4412 - val_acc: 0.8395 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "101/113 [=========================>....] - ETA: 0s - loss: 0.2234 - acc: 0.9554\n",
            "Epoch 00011: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2227 - acc: 0.9551 - val_loss: 0.4443 - val_acc: 0.8294 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.2100 - acc: 0.9581\n",
            "Epoch 00012: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2090 - acc: 0.9590 - val_loss: 0.4528 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.1976 - acc: 0.9657\n",
            "Epoch 00013: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1976 - acc: 0.9652 - val_loss: 0.4519 - val_acc: 0.8361 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1870 - acc: 0.9682\n",
            "Epoch 00014: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1868 - acc: 0.9682 - val_loss: 0.4610 - val_acc: 0.8361 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1799 - acc: 0.9703\n",
            "Epoch 00015: val_acc did not improve from 0.84281\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1772 - acc: 0.9710 - val_loss: 0.4614 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 16/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1690 - acc: 0.9707\n",
            "Epoch 00016: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1690 - acc: 0.9707 - val_loss: 0.4639 - val_acc: 0.8339 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "101/113 [=========================>....] - ETA: 0s - loss: 0.1636 - acc: 0.9746\n",
            "Epoch 00017: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1621 - acc: 0.9749 - val_loss: 0.4772 - val_acc: 0.8305 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1557 - acc: 0.9760\n",
            "Epoch 00018: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1545 - acc: 0.9769 - val_loss: 0.4780 - val_acc: 0.8350 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1482 - acc: 0.9791\n",
            "Epoch 00019: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1489 - acc: 0.9774 - val_loss: 0.4839 - val_acc: 0.8317 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.1427 - acc: 0.9798\n",
            "Epoch 00020: val_acc did not improve from 0.84281\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1441 - acc: 0.9788 - val_loss: 0.4852 - val_acc: 0.8294 - lr: 2.7000e-04\n",
            "Epoch 21/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1392 - acc: 0.9775\n",
            "Epoch 00021: val_acc did not improve from 0.84281\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1387 - acc: 0.9780 - val_loss: 0.4941 - val_acc: 0.8272 - lr: 2.4300e-04\n",
            "Epoch 00021: early stopping\n",
            "4Fold ACC = 0.8313253012048193\n",
            "\n",
            "Epoch 1/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 1.2061 - acc: 0.5358\n",
            "Epoch 00001: val_acc improved from -inf to 0.72687, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1840 - acc: 0.5482 - val_loss: 0.9177 - val_acc: 0.7269 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.7994 - acc: 0.8023\n",
            "Epoch 00002: val_acc improved from 0.72687 to 0.79264, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7933 - acc: 0.8016 - val_loss: 0.7046 - val_acc: 0.7926 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.6257 - acc: 0.8567\n",
            "Epoch 00003: val_acc improved from 0.79264 to 0.82274, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6189 - acc: 0.8584 - val_loss: 0.5649 - val_acc: 0.8227 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.4816 - acc: 0.8741\n",
            "Epoch 00004: val_acc improved from 0.82274 to 0.83389, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4784 - acc: 0.8760 - val_loss: 0.4897 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3988 - acc: 0.8955\n",
            "Epoch 00005: val_acc improved from 0.83389 to 0.84169, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3988 - acc: 0.8955 - val_loss: 0.4590 - val_acc: 0.8417 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.3455 - acc: 0.9178\n",
            "Epoch 00006: val_acc improved from 0.84169 to 0.84281, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3502 - acc: 0.9144 - val_loss: 0.4401 - val_acc: 0.8428 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.3158 - acc: 0.9275\n",
            "Epoch 00007: val_acc improved from 0.84281 to 0.84727, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3158 - acc: 0.9275 - val_loss: 0.4314 - val_acc: 0.8473 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.2891 - acc: 0.9333\n",
            "Epoch 00008: val_acc improved from 0.84727 to 0.84838, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2886 - acc: 0.9342 - val_loss: 0.4232 - val_acc: 0.8484 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2668 - acc: 0.9395\n",
            "Epoch 00009: val_acc did not improve from 0.84838\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2668 - acc: 0.9395 - val_loss: 0.4219 - val_acc: 0.8484 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.2490 - acc: 0.9459\n",
            "Epoch 00010: val_acc did not improve from 0.84838\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2486 - acc: 0.9459 - val_loss: 0.4192 - val_acc: 0.8473 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9534\n",
            "Epoch 00011: val_acc did not improve from 0.84838\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2327 - acc: 0.9535 - val_loss: 0.4195 - val_acc: 0.8450 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.2188 - acc: 0.9592\n",
            "Epoch 00012: val_acc did not improve from 0.84838\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2184 - acc: 0.9588 - val_loss: 0.4260 - val_acc: 0.8473 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.2070 - acc: 0.9620\n",
            "Epoch 00013: val_acc did not improve from 0.84838\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2066 - acc: 0.9621 - val_loss: 0.4243 - val_acc: 0.8473 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1950 - acc: 0.9638\n",
            "Epoch 00014: val_acc did not improve from 0.84838\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1950 - acc: 0.9638 - val_loss: 0.4302 - val_acc: 0.8462 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9693\n",
            "Epoch 00015: val_acc did not improve from 0.84838\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1852 - acc: 0.9691 - val_loss: 0.4289 - val_acc: 0.8473 - lr: 3.0000e-04\n",
            "Epoch 16/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9685\n",
            "Epoch 00016: val_acc did not improve from 0.84838\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1774 - acc: 0.9682 - val_loss: 0.4411 - val_acc: 0.8417 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1693 - acc: 0.9730\n",
            "Epoch 00017: val_acc improved from 0.84838 to 0.85173, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1693 - acc: 0.9730 - val_loss: 0.4387 - val_acc: 0.8517 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9729\n",
            "Epoch 00018: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1620 - acc: 0.9730 - val_loss: 0.4436 - val_acc: 0.8473 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9759\n",
            "Epoch 00019: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1553 - acc: 0.9763 - val_loss: 0.4520 - val_acc: 0.8450 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1493 - acc: 0.9766\n",
            "Epoch 00020: val_acc did not improve from 0.85173\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1493 - acc: 0.9766 - val_loss: 0.4508 - val_acc: 0.8428 - lr: 2.7000e-04\n",
            "Epoch 21/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1452 - acc: 0.9793\n",
            "Epoch 00021: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1444 - acc: 0.9794 - val_loss: 0.4605 - val_acc: 0.8428 - lr: 2.4300e-04\n",
            "Epoch 22/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1392 - acc: 0.9803\n",
            "Epoch 00022: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1392 - acc: 0.9799 - val_loss: 0.4682 - val_acc: 0.8328 - lr: 2.4300e-04\n",
            "Epoch 23/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9821\n",
            "Epoch 00023: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1347 - acc: 0.9824 - val_loss: 0.4631 - val_acc: 0.8439 - lr: 2.4300e-04\n",
            "Epoch 24/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1316 - acc: 0.9839\n",
            "Epoch 00024: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1309 - acc: 0.9841 - val_loss: 0.4777 - val_acc: 0.8350 - lr: 2.4300e-04\n",
            "Epoch 25/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1272 - acc: 0.9847\n",
            "Epoch 00025: val_acc did not improve from 0.85173\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00021870001510251313.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1272 - acc: 0.9847 - val_loss: 0.4722 - val_acc: 0.8328 - lr: 2.4300e-04\n",
            "Epoch 26/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9841\n",
            "Epoch 00026: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1227 - acc: 0.9841 - val_loss: 0.4727 - val_acc: 0.8384 - lr: 2.1870e-04\n",
            "Epoch 27/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1198 - acc: 0.9847\n",
            "Epoch 00027: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1198 - acc: 0.9847 - val_loss: 0.4779 - val_acc: 0.8384 - lr: 2.1870e-04\n",
            "Epoch 28/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1167 - acc: 0.9867\n",
            "Epoch 00028: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.1165 - acc: 0.9869 - val_loss: 0.4915 - val_acc: 0.8294 - lr: 2.1870e-04\n",
            "Epoch 29/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1136 - acc: 0.9857\n",
            "Epoch 00029: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1139 - acc: 0.9863 - val_loss: 0.4900 - val_acc: 0.8317 - lr: 2.1870e-04\n",
            "Epoch 30/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1103 - acc: 0.9875\n",
            "Epoch 00030: val_acc did not improve from 0.85173\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001968300188309513.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1103 - acc: 0.9875 - val_loss: 0.4878 - val_acc: 0.8283 - lr: 2.1870e-04\n",
            "Epoch 31/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9878\n",
            "Epoch 00031: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1072 - acc: 0.9877 - val_loss: 0.4950 - val_acc: 0.8305 - lr: 1.9683e-04\n",
            "Epoch 32/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1061 - acc: 0.9877\n",
            "Epoch 00032: val_acc did not improve from 0.85173\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1052 - acc: 0.9883 - val_loss: 0.5049 - val_acc: 0.8294 - lr: 1.9683e-04\n",
            "Epoch 00032: early stopping\n",
            "5Fold ACC = 0.8373493975903614\n",
            "\n",
            "Epoch 1/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 1.1842 - acc: 0.5490\n",
            "Epoch 00001: val_acc improved from -inf to 0.71126, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1816 - acc: 0.5513 - val_loss: 0.9169 - val_acc: 0.7113 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.7955 - acc: 0.8116\n",
            "Epoch 00002: val_acc improved from 0.71126 to 0.79153, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7896 - acc: 0.8124 - val_loss: 0.6991 - val_acc: 0.7915 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.6053 - acc: 0.8521\n",
            "Epoch 00003: val_acc improved from 0.79153 to 0.80602, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6031 - acc: 0.8531 - val_loss: 0.5578 - val_acc: 0.8060 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.8826\n",
            "Epoch 00004: val_acc improved from 0.80602 to 0.82609, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4638 - acc: 0.8824 - val_loss: 0.4933 - val_acc: 0.8261 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.3871 - acc: 0.9015\n",
            "Epoch 00005: val_acc did not improve from 0.82609\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3876 - acc: 0.9011 - val_loss: 0.4623 - val_acc: 0.8250 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3409 - acc: 0.9169\n",
            "Epoch 00006: val_acc improved from 0.82609 to 0.82832, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3409 - acc: 0.9169 - val_loss: 0.4484 - val_acc: 0.8283 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.3085 - acc: 0.9308\n",
            "Epoch 00007: val_acc improved from 0.82832 to 0.83278, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3075 - acc: 0.9306 - val_loss: 0.4392 - val_acc: 0.8328 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.2841 - acc: 0.9347\n",
            "Epoch 00008: val_acc improved from 0.83278 to 0.83835, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2823 - acc: 0.9370 - val_loss: 0.4336 - val_acc: 0.8384 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2607 - acc: 0.9454\n",
            "Epoch 00009: val_acc did not improve from 0.83835\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2607 - acc: 0.9454 - val_loss: 0.4330 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.2415 - acc: 0.9493\n",
            "Epoch 00010: val_acc did not improve from 0.83835\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2442 - acc: 0.9482 - val_loss: 0.4343 - val_acc: 0.8384 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "101/113 [=========================>....] - ETA: 0s - loss: 0.2283 - acc: 0.9539\n",
            "Epoch 00011: val_acc did not improve from 0.83835\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2283 - acc: 0.9537 - val_loss: 0.4325 - val_acc: 0.8328 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.2152 - acc: 0.9577\n",
            "Epoch 00012: val_acc improved from 0.83835 to 0.83946, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2154 - acc: 0.9571 - val_loss: 0.4357 - val_acc: 0.8395 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9626\n",
            "Epoch 00013: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2034 - acc: 0.9627 - val_loss: 0.4423 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1936 - acc: 0.9628\n",
            "Epoch 00014: val_acc did not improve from 0.83946\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1933 - acc: 0.9629 - val_loss: 0.4407 - val_acc: 0.8294 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9654\n",
            "Epoch 00015: val_acc improved from 0.83946 to 0.84392, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1845 - acc: 0.9654 - val_loss: 0.4481 - val_acc: 0.8439 - lr: 3.0000e-04\n",
            "Epoch 16/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 0.1783 - acc: 0.9663\n",
            "Epoch 00016: val_acc did not improve from 0.84392\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1757 - acc: 0.9677 - val_loss: 0.4551 - val_acc: 0.8406 - lr: 3.0000e-04\n",
            "Epoch 17/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1682 - acc: 0.9693\n",
            "Epoch 00017: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1675 - acc: 0.9699 - val_loss: 0.4587 - val_acc: 0.8317 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1606 - acc: 0.9721\n",
            "Epoch 00018: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1606 - acc: 0.9721 - val_loss: 0.4660 - val_acc: 0.8350 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9741\n",
            "Epoch 00019: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1558 - acc: 0.9741 - val_loss: 0.4738 - val_acc: 0.8350 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1510 - acc: 0.9748\n",
            "Epoch 00020: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1496 - acc: 0.9749 - val_loss: 0.4757 - val_acc: 0.8283 - lr: 2.7000e-04\n",
            "Epoch 21/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1447 - acc: 0.9777\n",
            "Epoch 00021: val_acc did not improve from 0.84392\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1441 - acc: 0.9769 - val_loss: 0.4767 - val_acc: 0.8350 - lr: 2.7000e-04\n",
            "Epoch 22/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1413 - acc: 0.9782\n",
            "Epoch 00022: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1391 - acc: 0.9791 - val_loss: 0.4900 - val_acc: 0.8294 - lr: 2.4300e-04\n",
            "Epoch 23/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1359 - acc: 0.9796\n",
            "Epoch 00023: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1349 - acc: 0.9794 - val_loss: 0.4809 - val_acc: 0.8227 - lr: 2.4300e-04\n",
            "Epoch 24/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1317 - acc: 0.9805\n",
            "Epoch 00024: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1317 - acc: 0.9805 - val_loss: 0.4960 - val_acc: 0.8305 - lr: 2.4300e-04\n",
            "Epoch 25/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9810\n",
            "Epoch 00025: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1273 - acc: 0.9813 - val_loss: 0.4938 - val_acc: 0.8205 - lr: 2.4300e-04\n",
            "Epoch 26/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9840\n",
            "Epoch 00026: val_acc did not improve from 0.84392\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00021870001510251313.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1233 - acc: 0.9841 - val_loss: 0.4997 - val_acc: 0.8261 - lr: 2.4300e-04\n",
            "Epoch 27/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1200 - acc: 0.9831\n",
            "Epoch 00027: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1199 - acc: 0.9830 - val_loss: 0.5087 - val_acc: 0.8305 - lr: 2.1870e-04\n",
            "Epoch 28/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1162 - acc: 0.9845\n",
            "Epoch 00028: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1167 - acc: 0.9844 - val_loss: 0.5061 - val_acc: 0.8205 - lr: 2.1870e-04\n",
            "Epoch 29/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1149 - acc: 0.9852\n",
            "Epoch 00029: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1139 - acc: 0.9858 - val_loss: 0.5208 - val_acc: 0.8261 - lr: 2.1870e-04\n",
            "Epoch 30/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9848\n",
            "Epoch 00030: val_acc did not improve from 0.84392\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1108 - acc: 0.9849 - val_loss: 0.5053 - val_acc: 0.8205 - lr: 2.1870e-04\n",
            "Epoch 00030: early stopping\n",
            "6Fold ACC = 0.8473895582329317\n",
            "\n",
            "Epoch 1/300\n",
            "102/113 [==========================>...] - ETA: 0s - loss: 1.2051 - acc: 0.5950\n",
            "Epoch 00001: val_acc improved from -inf to 0.70234, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1809 - acc: 0.6054 - val_loss: 0.9174 - val_acc: 0.7023 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.7893 - acc: 0.7847\n",
            "Epoch 00002: val_acc improved from 0.70234 to 0.77369, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7867 - acc: 0.7871 - val_loss: 0.6925 - val_acc: 0.7737 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.6002 - acc: 0.8575\n",
            "Epoch 00003: val_acc improved from 0.77369 to 0.79599, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.5993 - acc: 0.8581 - val_loss: 0.5579 - val_acc: 0.7960 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4647 - acc: 0.8760\n",
            "Epoch 00004: val_acc improved from 0.79599 to 0.82832, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4647 - acc: 0.8760 - val_loss: 0.4933 - val_acc: 0.8283 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.3886 - acc: 0.9031\n",
            "Epoch 00005: val_acc did not improve from 0.82832\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3893 - acc: 0.9030 - val_loss: 0.4654 - val_acc: 0.8227 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3426 - acc: 0.9150\n",
            "Epoch 00006: val_acc improved from 0.82832 to 0.83724, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3426 - acc: 0.9150 - val_loss: 0.4500 - val_acc: 0.8372 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.3094 - acc: 0.9322\n",
            "Epoch 00007: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3098 - acc: 0.9309 - val_loss: 0.4416 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.2835 - acc: 0.9369\n",
            "Epoch 00008: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2836 - acc: 0.9370 - val_loss: 0.4435 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.2616 - acc: 0.9438\n",
            "Epoch 00009: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2630 - acc: 0.9437 - val_loss: 0.4381 - val_acc: 0.8261 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.2439 - acc: 0.9492\n",
            "Epoch 00010: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2454 - acc: 0.9487 - val_loss: 0.4408 - val_acc: 0.8272 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.2287 - acc: 0.9561\n",
            "Epoch 00011: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2293 - acc: 0.9557 - val_loss: 0.4383 - val_acc: 0.8227 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9599\n",
            "Epoch 00012: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2164 - acc: 0.9588 - val_loss: 0.4425 - val_acc: 0.8227 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.2047 - acc: 0.9628\n",
            "Epoch 00013: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2048 - acc: 0.9629 - val_loss: 0.4488 - val_acc: 0.8205 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1915 - acc: 0.9679\n",
            "Epoch 00014: val_acc did not improve from 0.83724\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1931 - acc: 0.9671 - val_loss: 0.4525 - val_acc: 0.8183 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1835 - acc: 0.9699\n",
            "Epoch 00015: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1833 - acc: 0.9696 - val_loss: 0.4602 - val_acc: 0.8161 - lr: 2.7000e-04\n",
            "Epoch 16/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9696\n",
            "Epoch 00016: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1754 - acc: 0.9696 - val_loss: 0.4594 - val_acc: 0.8161 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1679 - acc: 0.9713\n",
            "Epoch 00017: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1681 - acc: 0.9707 - val_loss: 0.4673 - val_acc: 0.8149 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1638 - acc: 0.9736\n",
            "Epoch 00018: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1624 - acc: 0.9738 - val_loss: 0.4657 - val_acc: 0.8149 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1539 - acc: 0.9765\n",
            "Epoch 00019: val_acc did not improve from 0.83724\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1557 - acc: 0.9752 - val_loss: 0.4716 - val_acc: 0.8116 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.1491 - acc: 0.9763\n",
            "Epoch 00020: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1502 - acc: 0.9766 - val_loss: 0.4758 - val_acc: 0.8161 - lr: 2.4300e-04\n",
            "Epoch 21/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1439 - acc: 0.9786\n",
            "Epoch 00021: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1448 - acc: 0.9785 - val_loss: 0.4856 - val_acc: 0.8138 - lr: 2.4300e-04\n",
            "Epoch 00021: early stopping\n",
            "7Fold ACC = 0.8614457831325302\n",
            "\n",
            "Epoch 1/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 1.1976 - acc: 0.5382\n",
            "Epoch 00001: val_acc improved from -inf to 0.71460, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 2s 7ms/step - loss: 1.1783 - acc: 0.5516 - val_loss: 0.9165 - val_acc: 0.7146 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.7964 - acc: 0.8122\n",
            "Epoch 00002: val_acc improved from 0.71460 to 0.77926, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7941 - acc: 0.8116 - val_loss: 0.7075 - val_acc: 0.7793 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.6257 - acc: 0.8532\n",
            "Epoch 00003: val_acc improved from 0.77926 to 0.80936, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6208 - acc: 0.8551 - val_loss: 0.5706 - val_acc: 0.8094 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.4772 - acc: 0.8791\n",
            "Epoch 00004: val_acc improved from 0.80936 to 0.82943, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4737 - acc: 0.8804 - val_loss: 0.4930 - val_acc: 0.8294 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.3913 - acc: 0.9014\n",
            "Epoch 00005: val_acc improved from 0.82943 to 0.84058, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3904 - acc: 0.9019 - val_loss: 0.4587 - val_acc: 0.8406 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.3405 - acc: 0.9222\n",
            "Epoch 00006: val_acc did not improve from 0.84058\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3411 - acc: 0.9200 - val_loss: 0.4441 - val_acc: 0.8395 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.3055 - acc: 0.9322\n",
            "Epoch 00007: val_acc did not improve from 0.84058\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3070 - acc: 0.9312 - val_loss: 0.4340 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9392\n",
            "Epoch 00008: val_acc improved from 0.84058 to 0.84727, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2809 - acc: 0.9387 - val_loss: 0.4269 - val_acc: 0.8473 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.2592 - acc: 0.9451\n",
            "Epoch 00009: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2583 - acc: 0.9454 - val_loss: 0.4294 - val_acc: 0.8305 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.2412 - acc: 0.9485\n",
            "Epoch 00010: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2413 - acc: 0.9484 - val_loss: 0.4239 - val_acc: 0.8439 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.2257 - acc: 0.9517\n",
            "Epoch 00011: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2253 - acc: 0.9518 - val_loss: 0.4267 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.2129 - acc: 0.9589\n",
            "Epoch 00012: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2125 - acc: 0.9588 - val_loss: 0.4275 - val_acc: 0.8395 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9611\n",
            "Epoch 00013: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2006 - acc: 0.9615 - val_loss: 0.4347 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1917 - acc: 0.9644\n",
            "Epoch 00014: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1907 - acc: 0.9652 - val_loss: 0.4336 - val_acc: 0.8328 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1807 - acc: 0.9688\n",
            "Epoch 00015: val_acc did not improve from 0.84727\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1806 - acc: 0.9688 - val_loss: 0.4407 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 16/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1725 - acc: 0.9693\n",
            "Epoch 00016: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1715 - acc: 0.9696 - val_loss: 0.4429 - val_acc: 0.8339 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9730\n",
            "Epoch 00017: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1644 - acc: 0.9732 - val_loss: 0.4492 - val_acc: 0.8339 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "112/113 [============================>.] - ETA: 0s - loss: 0.1584 - acc: 0.9735\n",
            "Epoch 00018: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1583 - acc: 0.9735 - val_loss: 0.4523 - val_acc: 0.8361 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1510 - acc: 0.9759\n",
            "Epoch 00019: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1522 - acc: 0.9755 - val_loss: 0.4626 - val_acc: 0.8384 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.1468 - acc: 0.9759\n",
            "Epoch 00020: val_acc did not improve from 0.84727\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1466 - acc: 0.9760 - val_loss: 0.4629 - val_acc: 0.8395 - lr: 2.7000e-04\n",
            "Epoch 21/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1423 - acc: 0.9792\n",
            "Epoch 00021: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1417 - acc: 0.9791 - val_loss: 0.4685 - val_acc: 0.8417 - lr: 2.4300e-04\n",
            "Epoch 22/300\n",
            "111/113 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9794\n",
            "Epoch 00022: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1370 - acc: 0.9794 - val_loss: 0.4712 - val_acc: 0.8406 - lr: 2.4300e-04\n",
            "Epoch 23/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1333 - acc: 0.9804\n",
            "Epoch 00023: val_acc did not improve from 0.84727\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1328 - acc: 0.9805 - val_loss: 0.4730 - val_acc: 0.8395 - lr: 2.4300e-04\n",
            "Epoch 00023: early stopping\n",
            "8Fold ACC = 0.8253012048192772\n",
            "\n",
            "Epoch 1/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 1.1917 - acc: 0.5534\n",
            "Epoch 00001: val_acc improved from -inf to 0.66109, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1774 - acc: 0.5532 - val_loss: 0.9143 - val_acc: 0.6611 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.7918 - acc: 0.7609\n",
            "Epoch 00002: val_acc improved from 0.66109 to 0.80268, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7893 - acc: 0.7634 - val_loss: 0.6997 - val_acc: 0.8027 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.6112 - acc: 0.8589\n",
            "Epoch 00003: val_acc improved from 0.80268 to 0.81828, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6085 - acc: 0.8567 - val_loss: 0.5579 - val_acc: 0.8183 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.8793\n",
            "Epoch 00004: val_acc improved from 0.81828 to 0.82832, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.4684 - acc: 0.8799 - val_loss: 0.4913 - val_acc: 0.8283 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.3923 - acc: 0.8968\n",
            "Epoch 00005: val_acc improved from 0.82832 to 0.83055, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3919 - acc: 0.8980 - val_loss: 0.4594 - val_acc: 0.8305 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.3450 - acc: 0.9143\n",
            "Epoch 00006: val_acc improved from 0.83055 to 0.83724, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3445 - acc: 0.9147 - val_loss: 0.4450 - val_acc: 0.8372 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.3096 - acc: 0.9254\n",
            "Epoch 00007: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3099 - acc: 0.9242 - val_loss: 0.4353 - val_acc: 0.8372 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.2820 - acc: 0.9393\n",
            "Epoch 00008: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2831 - acc: 0.9384 - val_loss: 0.4307 - val_acc: 0.8328 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.2612 - acc: 0.9470\n",
            "Epoch 00009: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2611 - acc: 0.9473 - val_loss: 0.4300 - val_acc: 0.8317 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.2421 - acc: 0.9528\n",
            "Epoch 00010: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2426 - acc: 0.9529 - val_loss: 0.4316 - val_acc: 0.8372 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.2299 - acc: 0.9552\n",
            "Epoch 00011: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2274 - acc: 0.9568 - val_loss: 0.4391 - val_acc: 0.8317 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.2128 - acc: 0.9624\n",
            "Epoch 00012: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2139 - acc: 0.9604 - val_loss: 0.4350 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1991 - acc: 0.9638\n",
            "Epoch 00013: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2009 - acc: 0.9635 - val_loss: 0.4442 - val_acc: 0.8317 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1899 - acc: 0.9673\n",
            "Epoch 00014: val_acc did not improve from 0.83724\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1909 - acc: 0.9668 - val_loss: 0.4458 - val_acc: 0.8305 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1815 - acc: 0.9673\n",
            "Epoch 00015: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1808 - acc: 0.9677 - val_loss: 0.4469 - val_acc: 0.8261 - lr: 2.7000e-04\n",
            "Epoch 16/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1727 - acc: 0.9699\n",
            "Epoch 00016: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1736 - acc: 0.9693 - val_loss: 0.4561 - val_acc: 0.8272 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "110/113 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9705\n",
            "Epoch 00017: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1668 - acc: 0.9707 - val_loss: 0.4628 - val_acc: 0.8239 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1598 - acc: 0.9757\n",
            "Epoch 00018: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1594 - acc: 0.9749 - val_loss: 0.4650 - val_acc: 0.8216 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1524 - acc: 0.9761\n",
            "Epoch 00019: val_acc did not improve from 0.83724\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1530 - acc: 0.9755 - val_loss: 0.4705 - val_acc: 0.8261 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1492 - acc: 0.9752\n",
            "Epoch 00020: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1473 - acc: 0.9766 - val_loss: 0.4764 - val_acc: 0.8172 - lr: 2.4300e-04\n",
            "Epoch 21/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1417 - acc: 0.9783\n",
            "Epoch 00021: val_acc did not improve from 0.83724\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1417 - acc: 0.9783 - val_loss: 0.4789 - val_acc: 0.8227 - lr: 2.4300e-04\n",
            "Epoch 00021: early stopping\n",
            "9Fold ACC = 0.8393574297188755\n",
            "\n",
            "Epoch 1/300\n",
            "113/113 [==============================] - ETA: 0s - loss: 1.1750 - acc: 0.5981\n",
            "Epoch 00001: val_acc improved from -inf to 0.72352, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1750 - acc: 0.5981 - val_loss: 0.9126 - val_acc: 0.7235 - lr: 3.0000e-04\n",
            "Epoch 2/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.7921 - acc: 0.7948\n",
            "Epoch 00002: val_acc improved from 0.72352 to 0.78149, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7866 - acc: 0.7991 - val_loss: 0.6979 - val_acc: 0.7815 - lr: 3.0000e-04\n",
            "Epoch 3/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.6072 - acc: 0.8541\n",
            "Epoch 00003: val_acc improved from 0.78149 to 0.81494, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6044 - acc: 0.8542 - val_loss: 0.5604 - val_acc: 0.8149 - lr: 3.0000e-04\n",
            "Epoch 4/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.4694 - acc: 0.8792\n",
            "Epoch 00004: val_acc improved from 0.81494 to 0.83166, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4659 - acc: 0.8818 - val_loss: 0.4953 - val_acc: 0.8317 - lr: 3.0000e-04\n",
            "Epoch 5/300\n",
            "109/113 [===========================>..] - ETA: 0s - loss: 0.3892 - acc: 0.9062\n",
            "Epoch 00005: val_acc improved from 0.83166 to 0.83389, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3901 - acc: 0.9055 - val_loss: 0.4657 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 6/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.3425 - acc: 0.9233\n",
            "Epoch 00006: val_acc did not improve from 0.83389\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3429 - acc: 0.9231 - val_loss: 0.4506 - val_acc: 0.8294 - lr: 3.0000e-04\n",
            "Epoch 7/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.3093 - acc: 0.9284\n",
            "Epoch 00007: val_acc improved from 0.83389 to 0.84281, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3094 - acc: 0.9284 - val_loss: 0.4399 - val_acc: 0.8428 - lr: 3.0000e-04\n",
            "Epoch 8/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.2834 - acc: 0.9404\n",
            "Epoch 00008: val_acc improved from 0.84281 to 0.84504, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2837 - acc: 0.9392 - val_loss: 0.4346 - val_acc: 0.8450 - lr: 3.0000e-04\n",
            "Epoch 9/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.2604 - acc: 0.9466\n",
            "Epoch 00009: val_acc improved from 0.84504 to 0.84615, saving model to 1st_model.h5\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2626 - acc: 0.9451 - val_loss: 0.4312 - val_acc: 0.8462 - lr: 3.0000e-04\n",
            "Epoch 10/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.2470 - acc: 0.9486\n",
            "Epoch 00010: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2456 - acc: 0.9484 - val_loss: 0.4336 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 11/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.2283 - acc: 0.9533\n",
            "Epoch 00011: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2294 - acc: 0.9529 - val_loss: 0.4355 - val_acc: 0.8317 - lr: 3.0000e-04\n",
            "Epoch 12/300\n",
            "103/113 [==========================>...] - ETA: 0s - loss: 0.2165 - acc: 0.9569\n",
            "Epoch 00012: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2168 - acc: 0.9565 - val_loss: 0.4360 - val_acc: 0.8350 - lr: 3.0000e-04\n",
            "Epoch 13/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.2012 - acc: 0.9635\n",
            "Epoch 00013: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2041 - acc: 0.9615 - val_loss: 0.4416 - val_acc: 0.8328 - lr: 3.0000e-04\n",
            "Epoch 14/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1945 - acc: 0.9657\n",
            "Epoch 00014: val_acc did not improve from 0.84615\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002700000128243119.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1940 - acc: 0.9660 - val_loss: 0.4487 - val_acc: 0.8339 - lr: 3.0000e-04\n",
            "Epoch 15/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1843 - acc: 0.9676\n",
            "Epoch 00015: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1836 - acc: 0.9674 - val_loss: 0.4529 - val_acc: 0.8227 - lr: 2.7000e-04\n",
            "Epoch 16/300\n",
            "106/113 [===========================>..] - ETA: 0s - loss: 0.1769 - acc: 0.9696\n",
            "Epoch 00016: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1770 - acc: 0.9685 - val_loss: 0.4550 - val_acc: 0.8272 - lr: 2.7000e-04\n",
            "Epoch 17/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1691 - acc: 0.9719\n",
            "Epoch 00017: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1701 - acc: 0.9716 - val_loss: 0.4607 - val_acc: 0.8317 - lr: 2.7000e-04\n",
            "Epoch 18/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1608 - acc: 0.9741\n",
            "Epoch 00018: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1625 - acc: 0.9732 - val_loss: 0.4628 - val_acc: 0.8239 - lr: 2.7000e-04\n",
            "Epoch 19/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1559 - acc: 0.9752\n",
            "Epoch 00019: val_acc did not improve from 0.84615\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00024300001678057015.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1568 - acc: 0.9746 - val_loss: 0.4706 - val_acc: 0.8272 - lr: 2.7000e-04\n",
            "Epoch 20/300\n",
            "108/113 [===========================>..] - ETA: 0s - loss: 0.1493 - acc: 0.9763\n",
            "Epoch 00020: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1500 - acc: 0.9758 - val_loss: 0.4800 - val_acc: 0.8227 - lr: 2.4300e-04\n",
            "Epoch 21/300\n",
            "105/113 [==========================>...] - ETA: 0s - loss: 0.1467 - acc: 0.9777\n",
            "Epoch 00021: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1461 - acc: 0.9771 - val_loss: 0.4764 - val_acc: 0.8227 - lr: 2.4300e-04\n",
            "Epoch 22/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1414 - acc: 0.9787\n",
            "Epoch 00022: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1406 - acc: 0.9791 - val_loss: 0.4845 - val_acc: 0.8216 - lr: 2.4300e-04\n",
            "Epoch 23/300\n",
            "107/113 [===========================>..] - ETA: 0s - loss: 0.1369 - acc: 0.9798\n",
            "Epoch 00023: val_acc did not improve from 0.84615\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1362 - acc: 0.9802 - val_loss: 0.4895 - val_acc: 0.8216 - lr: 2.4300e-04\n",
            "Epoch 24/300\n",
            "104/113 [==========================>...] - ETA: 0s - loss: 0.1302 - acc: 0.9808\n",
            "Epoch 00024: val_acc did not improve from 0.84615\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00021870001510251313.\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1316 - acc: 0.9799 - val_loss: 0.4864 - val_acc: 0.8216 - lr: 2.4300e-04\n",
            "Epoch 00024: early stopping\n",
            "10Fold ACC = 0.857429718875502\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred = [1 if p >= 0.5 else 0 for p in model1_pred]"
      ],
      "metadata": {
        "id": "ZsBzb3QP4QAZ"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "h-hDk_iu4Xbj"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['label'] = final_pred"
      ],
      "metadata": {
        "id": "Askw8GMM4a8U"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBjBZhW04dDY",
        "outputId": "e27150e8-3d18-483c-a081-0480a0be2e8e"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2602\n",
              "1    2398\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"dl_1st.csv\", index = False)"
      ],
      "metadata": {
        "id": "XEYg2fng4e55"
      },
      "execution_count": 164,
      "outputs": []
    }
  ]
}